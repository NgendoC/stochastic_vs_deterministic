%%%%%%%%%%%%%%%%%%%%%
%% Document set-up %%
%%%%%%%%%%%%%%%%%%%%%

% Requirements:
  % Double-spaced
  % minimum 11pt font
  % Arial or Verdana font
  % 2 cm margins

\documentclass[a4paper, 11pt]{article} % sets document shape and font size

\usepackage[margin=2.0cm]{geometry} % set margins to 2cm
% \usepackage[document]{ragged2e} % make text left-aligned

\usepackage{setspace, caption}
\captionsetup{font=doublespacing} %double-spaced float captions
\doublespacing %double-spaced document

% change font to Arial
\renewcommand{\rmdefault}{phv} % Arial
\renewcommand{\sfdefault}{phv} % Arial

\renewcommand*\contentsname{} % removes Table of Contents' title

\usepackage{amsmath} % Needed for maths equations
\usepackage{graphicx}
\graphicspath{ {/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Plots/} } % Where the images will be found 
% \graphicspath{ {/Work_folder/Plots/} } %

\usepackage{natbib}
\bibliographystyle{unsrtnat}

% for creating a flow chart
\usepackage{tikz} 
\usetikzlibrary{shapes.geometric, arrows}
\tikzstyle{sir} = [rectangle, rounded corners, minimum width=3cm, minimum height=1cm,text centered, draw=black, fill=red!0]
\tikzstyle{arrow} = [thick,->,>=stealth]

\usepackage{multirow} % for combining rows in tables

\usepackage{float} % for forcing figure placement

\usepackage{fontspec}

%%%%%%%%%%%%%%%%%%%%%%%
%% Start of document %%
%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\SweaveOpts{concordance=TRUE}
\setmainfont[Ligatures=TeX]{Verdana}

%%%%%%%%%%%
%% Title %%
%%%%%%%%%%%

\begin{titlepage}
    \begin{center}
        \vspace*{2.5cm}
        
        \textbf{Comparing methods from deterministic and stochastic infectious disease modelling for parameter inference}
        
        \vspace{0.5cm}
        Project 1
        
        MRes Biomedical Research 
        
        Epidemiology, Evolution, and Control of Infectious Diseases Stream 
        
        \vspace{0.5cm}
        
        \textbf{Janetta E. Skarp}
        
        \vspace{2.5cm}
        
        \includegraphics[width=0.4\textwidth]{ICL_crest}
        % \includegraphics{ICL_crest.png}
        
        \vspace{2.5cm}
        
        Supervisor: Xavier Didelot\\ 
        Submitted: March 2018\\
        Department of Surgery and Cancer, Imperial College London
        
    \end{center}
    
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Originality statement %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statement of Originality}

I certify that this thesis, and the research to which it refers, are the product of my own work, conducted during the current year of the MRes in Biomedical Research at Imperial College London. Any ideas or quotations from the work of other people, published or otherwise, or from my own previous work are fully acknowledged in accordance with the standard referencing practices of the discipline.
% Also acknowledge work of other researchers if necessary e.g. if you got samples from someone else.

%%%%%%%%%%%%%%
%% Abstract %%
%%%%%%%%%%%%%%

\newpage
\section{Abstract}
\noindent \textbf{Background} Different methods exist for inferring the ranges of values that a parameter might take in a model. These methods can broadly be categorised into deterministic methods, such as the residual error (RE) method, and stochastic methods, such as the Markov Chain Monte Carlo (MCMC) method.

\noindent \textbf{Aim} The aim of this project is to elucidate the conditions under which the residual error method, might be used just as well as the MCMC, if one is trying to quantify the range of values that a parameter might take.

\noindent \textbf{Methods} I created a stochastic population based closed compartmental SIR model. With this model, I generated altogether 30 different outbreaks for 6 different scenarios: with an $R_{0}$ of 1.5 or 6 with a population size of 50, 200, and 1000, with five repeats per type of combination. I then built RE and MCMC parameter inference methods and inferred the values that $\beta$ and $\gamma$ may take for each outbreak based on the recovery curve obtained from the generated outbreaks. A MCMC with a deterministic process was also explored.

\noindent \textbf{Results} The RE inference method consistently produced narrower ranges for parameter estimates than the MCMC. When comparing RE estimates between outbreaks with $R_{0}$s of 1.5 and 6, it seemed that the parameter estimates were more consistent for outbreaks with the higher $R_{0}$. 

\noindent \textbf{Conclusions}
% 0.5 to 1 page

%%%%%%%%%%%%%%%%%%%%%%
%% Acknowledgements %%
%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Acknowledgements}

I would like to thank my supervisor, Dr Xavier Didelot, for his help and advice with this project.

%%%%%%%%%%%%%%%%%%%%%%%
%% Table of contents %%
%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Table of Contents}
\tableofcontents

%%%%%%%%%%%%%%%%%%%
%% Abbreviations %%
%%%%%%%%%%%%%%%%%%%

\newpage
\section{Abbreviations}
MCMC: Markov Chain Monte Carlo

\noindent $R_{0}$: basic reproduction number

\noindent RE: residual error

\noindent SIR: susceptible, infected, recovered

%%%%%%%%%%%%%%%%%%
%% Introduction %%
%%%%%%%%%%%%%%%%%%

\newpage
\section{Introduction}
% 5-10 pages

\textbf{Note} - I'll be adding citations to the compartmental model part of the introduction. Anderson and May Infectious Diseases of Humans

%%%%%%%%%%

\subsection{Compartmental models in infectious disease epidemiology}
Compartmental models have been used to model the movement of diseases in populations since their introduction to the field of epidemiology during the first half of the 20th century. Kermack and McKendrick were among the pioneers of this new method and in their joint paper published in 1927 they outlined how compartmental models could be used for infectious disease epidemiology \citep{Kermack1927}. As the name of the model suggests, a compartmental model splits the model population into different compartments depending on factors defined by the investigator, such as disease status or age group.     
% Kermack and McKendrick 1927: http://rspa.royalsocietypublishing.org/content/royprsa/115/772/700.full.pdf

% SIR figure
\begin{figure}[H]
\begin{center}
\begin{tikzpicture}[node distance=5cm]
\node (S) [sir] {S};
\node (I) [sir, right of =S] {I};
\node (R) [sir, right of=I] {R};
\draw [arrow] (S) -- node[anchor=south] {$\beta S I$} (I);
\draw [arrow] (I) -- node[anchor=south] {$\gamma I$} (R);
\end{tikzpicture}
\caption{A closed compartmental SIR model. S: susceptible, I: infectious, R: recovered, $\beta$ rate at which an individual becomes infected, $\gamma$ rate of recovery}
\end{center}
\end{figure}

One commonly used compartmental model is the SIR model which consists of three compartments: susceptible, infected, and recovered. This type of SIR model is referred to as being closed, as there is no flow of individuals into the population or out of the population (i.e. births, deaths, or migration). 

There are two ways to implement an SIR model, the deterministic and stochastic method. For both a stochastic and deterministic SIR model, the population moves from the susceptible compartment to the infected compartment and from the infected compartment to the recovered compartment with some rate $\beta$ and $\gamma$, respectively (Figure). The deterministic model is usually implemented in continuous time, implying that the difference between timesteps is vanishingly small resulting in the flows between compartments being described as differential equations:
\begin{align*}
\frac{dS}{dt} &= - \beta S I \\
\frac{dI}{dt} &= \beta S I - \gamma I \\
\frac{dR}{dt} &= \gamma I
\end{align*}

\noindent As susceptibles need to come into contact with infected individuals in order to become infected themselves, $\beta$ is multiplied by the number of contacts made between members of the susceptible and infected compartments, which then results in the number of people who become newly infected. Given that $\beta$ refers to the rate at which individuals become infected, the number of contacts is calculated by taking the product of the number of individuals susceptible and the number of individuals infected. In order to calculate the number of infected individuals moving to the recovered compartment, $\gamma$ is multiplied by the number of infected individuals.

Stochastic models can be used in continuous time, but it is often convenient to discretise time. Differences between timesteps are larger for discrete than continuous time. Therefore, the number of individuals in a given compartment at a given timestep is calculated from the previous timestep:
\begin{align*}
S_{i+1} &= S_{i} - b_{i} \\
I_{i+1} &= I_{i} + b_{i} - c_{i} \\
R_{i+1} &= R_{i} + c{i}
\end{align*}

\noindent Here $S_{i}$, $I_{i}$, and $R_{i}$ refer to the number of individuals in each compartment at timestep $i$, while $S_{i+1}$, $I_{i+1}$, and $R_{i+1}$ refer to the numbers of individuals in the susceptible, infected, and recovered compartments at the next timestep $i+1$. $b_{i}$ and $c_{i}$ refer to the number of newly infected and newly recovered individuals at timestep $i$ respectively.

The number of individuals joining the infected compartment, $b_{i}$, or recovered compartment, $c_{i}$ at timestep $i$ can be chosen randomly from a binomial distribution: 
\begin{align*}
b_{i} &\sim Bin(S_{i}, 1 - e^{-\beta I_{i} dt}) \\
c_{i} &\sim Bin(I_{i}, 1 - e^{-\gamma dt})
\end{align*}

\noindent where $S_{i}$, $I_{i}$, and $R_{i}$ represent the number of susceptible, infected, and recovered individuals at time i respectively. The size of a timestep is referred to by $dt$. From this, the numbers of susceptible, infected, and recovered individuals at time $i+1$ could thus be calculated.

When one is deciding on a compartmental model to use, the differences between the two modelling methods should be taken into consideration. One of the major differences between the two is that a deterministic compartmental model always produces the same outcome when given the same input, while stochastic models show changing outcomes with every run of the same input. Additionally, deterministic models are often easier to implement than stochastic models. This is due to deterministic models making simplifying assumptions about population dynamics. These assumptions include the concept of a fraction of a person being infected and that given that the same proportion of people are infected at the start and there being no difference between a large and a small population size. Deterministic models also require less computational power as every run is the same and therefore runs do not need to be repeated. Stochastic models, on the other hand, may be better for smaller populations where stochasticity of events is more pronounced and events such as epidemic fadeout are a more likely scenario than in bigger populations. 

When a model is being chosen, a researcher may not always ponder about what the best modelling strategy is for the task at hand, but rather use the method that they understand best or habitually use. As computers have become more powerful, the production of more computationally demanding stochastic models has gained popularity. This could be because of the acknowledgement of all epidemics originally being stochastic processes. Sometimes the conclusions reached with the aid of stochastic and deterministic compartmental models may be similar, in which case one might think that a deterministic model should be favoured due it being less computationally taxing and more straightforward. 

Though compartmental models are useful for infectious disease modelling, it should be noted that they are not the only modelling method, and that there are cases for which neither the stochastic nor the deterministic compartmental model is the best model for the task at hand. An example of such a scenario would be modelling the spread of STIs, for which network modelling methods are also popular (Garnett, 2001).
% Paper for STI modelling methods: Garnett 2001 http://sti.bmj.com/content/sextrans/78/1/7.full.pdf

%%%%%%%%%%

\subsection{Inference for compartmental infectious disease models}
% Base this section on papers discussed with Xavier

The residual error (RE) method can be used for inference under a deterministic model. The aim of this method is to minimise the discrepency between observed and expected data, calculated as the sum of squared difference between the value obtained from the model and the true data value. This is done through optimisation, where starting values for parameters are set, a deterministic model is simulated based on these chosen parameter values, the sum of swuated is calculated, and the process is repeated until the RE is at a minimum. Ultimately, the aim of using this method is to retain the point estimate, the parameter combination that produces the lowest residual error. The point estimate corresponds to the best fit of the deterministic model to the incomplete data being fitted. One limitation of the RE method is that it does not capture the uncertainty in the parameter values, as it only calculates the point estimate.

Bootstrapping can be used to investigate the sensitivity of the best guess parameter combinations to slight changes in the data. This can be achieved by sampling with replacement from the data and repeating the optimisation process to reach the lowest RE as was done for the original dataset to obtain the point estimate.    

Bayesian statistics can also be applied in order to infer ranges of values that a parameter in a model might take, typically through the usage of Markov Chain Monte Carlo methods. Bayes' theorem lies at the heart of Bayesian statistics and states that:
\begin{align*}
P(\theta \mid x) \propto P(x \mid \theta)P(\theta)
\end{align*}
\noindent The prior distribution is often defined as $P(\theta)$, the probability distribution of the values that the parameters in question might take before the data is observed. This is defined by the investigators' best guess for the values that parameters might take before taking into consideration the new data. $P(x \mid \theta)$, the likelihood function, refers to the probability of the observed data, $x$ occurring given the parameter value, $\theta$. The likelihood function can be multiplied by the prior distribution to produce the posterior distribution, $P(x \mid \theta)$, the probability of the parameter value given the data. 

The Markov Chain Monte Carlo inference method is rooted in Bayesian statistics. A random walk MCMC works by first setting a starting value for the parameter in question, and then randomly choosing another parameter value from a proposal distribution devised by the investigator. Such a distribution may for example be Normal with a mean of the current parameter value and a predefined standard deviation. It then calculates the posterior distribution for both the current parameter value and the proposed parameter value. The resulting posterior distributions are then compared by dividing the proposed posterior by the current posterior. If the resulting proportion is greater than 1, it implies that the proposed parameter value is more probable given the observed data and will take the place of the starting value as the new baseline parameter value. This will then be compared to a new proposed parameter value in the next iteration of the MCMC. A worse proposed posterior than current posterior is accepted by choosing a random number from a uniform distribution between 0 and 1 and accepting the proposed posterior if it is greater than this random number. This will lead to the proposed posterior to sometimes being accepted even if the proposed to baseline posterior ratio is less than 1. MCMC methods can also used for estimating an outbreak curve from a recovery curve, as was originally demonstrated by O'Neill et al. \citep{ONeill1999}. DISCUSS UNCERTAINTY!

Stochastic methods, such as the MCMC, can be more difficult to implement than deterministic ones, such as the RE method. In order to have an optimally working MCMC, it may for example take multiple attempts to calibrate the proposal function to result in a sufficient acceptance rate of proposed parameters. Additionally, running a MCMC to completion often takes longer than for a RE. Additionally, constructing a MCMC from scratch is more demanding than constructing a RE, due to there being many distributions, the prior, likelihood, and proposal, to consider for each parameter of interest.  Also, the data available for model parameter inference should be considered, though it will not be explored in this project. If many factors are unknown, a complex stochastic modelling method making a multitude of assumptions may perform worse than a simpler deterministic model (mention HIV modelling or FMD example? - May 2003). 
% Find a couple of examples where the model used for the task may not have been the best?
% May (2003) Uses and abuses of mathematics in biology : Complex HIV model lost to a less complex model because the assumptions it made were wrong 

\newpage
\subsection{Aims of this project}
In this project, I compare the parameter estimates of stochastic and deterministic models under different population settings. The aim of this is to elucidate the conditions under which a deterministic model, such as the residual error method, might be used just as well as a stochastic one, such as the MCMC, if one is trying to quantify the range of values that a parameter might take.

In light of the suggestion that deterministic parameterisation methods are quicker, one might ask if the two could be combined to distil the best of both methods. MCMC has been combined with a deterministic process, for example in a paper exploring public health responses to bioterrorism \citep{Elderd2006}. This method is also briefly explored in this project.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Materials and methods %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\section{Materials and Methods}
% 5-10 pages

All data generation and analysis presented in this report was conducted on R, a statistical computing language (R Core Team, 2017).

%%%%%%%%%%

\subsection{Simulating data for fitting}

I used a stochastic population-based closed compartmental SIR model, such as the one described in the introduction, to generate outbreaks with various basic reproduction numbers ($R_{0}$) in different-sized populations. 

I chose two different epidemic outbreak scenarios, one with an underlying $R_{0}$ of 1.5, on the lower end for a disease that could still cause an outbreak, and the other with a higher underlying $R_{0}$ of 6. Here $R_{0}$ refers to the number of susceptible individuals that an infectious individual would successfully infect in a completely susceptible population. Both scenarios had a probability of recovery at a given timepoint, $\gamma$, of 0.15. Thus, the underlying the per capita probability of infection, $\beta$, for the outbreaks could be calculated as 
\begin{align*}
\beta = \frac{R_{0} \times \gamma}{N}
\end{align*}

\noindent where N is the population size. Three different population sizes were also considered for both of the two outbreak scenarios: a small population size of 50, a medium population size of 200, and a large population size of 1000. The proportion of the population that was infected in each population at the beginning of the simulation was kept constant with 1 infectious individual in the population of 50, 4 infectious individuals in the population of 200, and 20 infectious individuals in the population of 1000. For each of the underlying outbreak strength and population size combinations (six combinations in total), five different epidemics were generated with the devised stochastic model. Thus altogether, the stochastic population-based closed compartmental SIR model described in the introduction was used to devise 30 distinct outbreaks. Each outbreak was set to be observed for 80 days at 0.5-day timesteps.

I then created a closed population stochastic SIR model, as outlined in the introduction. From the output of this model, I used the recovery curves and various inference methods to estimate parameter value ranges, such as $\beta$ and $\gamma$, or missing data, such as the infectious curve. The estimates made through these methods could then be compared to the true underlying values, as they are also known.

%%%%%%%%%%

\subsection{Parameterisation}

\subsubsection{Residual error}

I used the residual error method to infer the values of $\beta$ and $\gamma$ given the recovered curve from the generated data made by the stochastic model. Firstly, I constructed a deterministic SIR model with the aid of \textit{deSolve}, a differential equation solving R package (Soetaert et al., 2010). I then optimised the deterministic model's fit to the recovered curve of the generated data to receive a point estimate for the $\beta$ and $\gamma$ for each outbreak in addition the best-fit deterministic infectious curve. The fit of the model during the optimisation process was calculated as the sum of the squared differences between the model, $d_{model}^i$, and observation, $d_{observation}^i$, for each timepoint $i$:

\begin{align*}
\displaystyle\sum_{i}(d_{model}^i - d_{observation}^i)^2
\end{align*}

I gauged the accuracy of the point estimate by bootstrapping. I achieved this by sampling timepoints with replacement from the original generated recovered curve for a given outbreak and optimising the deterministic model on that sampled curve. This would then bring into light whether there were any particular timepoints that might be driving the results of the optimisation process. 

% Use R command citation() to figure out how to cite R packages e.g. citation(package = "deSolve")

%%%%%%%%%%

\subsubsection{Markov Chain Monte Carlo}

I used a Metropolis-Hastings algorithm to infer the values of $\beta$ and $\gamma$ from an incomplete version of the data generated with the stochastic SIR model I created. 

I calculated the likelihood distribution as follows: 
\begin{align*}
\displaystyle\prod_{i=1}^{N}p(b_{i}, c_{i} \mid \beta, \gamma)
\end{align*}

\noindent where
\begin{align*}
p(b_{i}, c_{i} \mid \beta, \gamma) = Bin(b_{i} \mid S_{i}, 1-e^{-\beta I_{i} dt}) \times Bin(c_{i} \mid I_{i}, 1-e^{-\gamma dt})
\end{align*}

The prior distributions for $\beta$ and $\gamma$ were set to be uniform between the values of 0 and 100, implying that there was no original guess at the value that $\beta$ and $\gamma$ should take. The posterior distribution was then calculated as $likelihood \times prior$. When assembling the MCMC algorithm, the equations above were done in logarithmic form to avoid floating point inaccuracies.

The MCMC was then adapted to perform data augmentation on the infectious curve, meaning that it was to guess the number of infectious individuals at each timestep $i$. A first guess of the infectious curve was obtained by guessing an initial $\gamma$ value, assuming a constant infectious period, and thus back-calculating the infectious curve from the known recovered curve. This original infectious curve was then changed by proposing the addition or subtraction one infectious person from a given timepoint $i$ and moving them to a randomly chosen neighbouring timepoint at every iteration of the MCMC.

Whether or not a proposed change in $\beta$, $\gamma$ or the infectious curve is accepted was calculated with the Metropolis-Hastings ratio, where the proposed change is accepted if the ratio of the proposed posterior to the existing posterior is higher than a randomly selected number from a uniform distribution between 0 and 1. This means that the move is always accepted if the proposed posterior is greater than the existing posterior, and that less advantageous moves are also occasionally accepted to allow for movement out of possible local maximum. 

For the generated data with an underlying $R_{0}$ of 1.5 and $\gamma$ of 0.15, the MCMC starting points were set to 1.2 for $R_{0}$ and 0.10 for $\gamma$. For the outbreaks with underlying $R_{0}$ of 6 and $\gamma$ of 0.15, the MCMC starting points were set to 7.2 for $R_{0}$ and 0.10 for $\gamma$. Each MCMC was run for 3.5 million iterations.

%%%%%%%%%%

\subsubsection{Markov Chain Monte Carlo with a partly deterministic process}

I altered the stochastic MCMC I had previously created in the previous section to only have two unknown parameters, $\beta$ and $\gamma$. I then changed the likelihood function so that it created a deterministic SIR model for every set of $\beta$ and $\gamma$ tested. I used the \textit{deSolve} package to construct the deterministic model (Soetaert et al., 2010). The number of infectious individuals from the output of the deterministic model was then rounded to the nearest integer for each time step to avoid partial individuals from being infected. The susceptible curve was devised from the known stochastic recovered curve, $R_{i}$ and the deterministic infectious curve, $I_{i}$ so that
\begin{align*}
S_{i} &= N - I_{i} - R_{i}
\end{align*}
where $N$ represents the total population size.

Similarly, the number of newly infected individuals, $b$, for each time step $i$ was also affected by the deterministic infectious curve, $I^{d}$, and the stochastic recovered curve:
\begin{align*}
b_{i+1} &= I_{i+1}^{d} - I_{i}^{d} + R_{i+1} - R_{i}
\end{align*}

%%%%%%%%%%

%%%%%%%%%%%%%
%% Results %%
%%%%%%%%%%%%%

\newpage
\section{Results}
% 10-15 pages

%%%%%%%%%%

\subsection{The simulated outbreaks}

Six different outbreak scenarios were created: an outbreak with an $R_{0}$ of 1.5 and 6 for population sizes of 50, 200, and 1000 individuals. The initial proportion of infectious individuals at the beginning of each outbreak was the same for each population size. Five different outbreaks were constructed for each of the six scenarios. Figures 2 and 3 show the shapes for each generated outbreak.
\newline

\begin{figure}[h]
\begin{center}
<<dataplot1, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, fig.pos="H", height=13, width=17, fig.lp = "Figure", fig.cap="Data plot", fig=TRUE>>=
# R0 = 1.5

# setwd("/home/evelina/Development/stochastic_vs_deterministic/")
true_R1.5_pop50_seed1 <- read.csv("data_pop50_R1.5_g0.15_14.csv")
true_R1.5_pop50_seed2 <- read.csv("data_pop50_R1.5_g0.15_22.csv")
true_R1.5_pop50_seed3 <- read.csv("data_pop50_R1.5_g0.15_40.csv")
true_R1.5_pop50_seed4 <- read.csv("data_pop50_R1.5_g0.15_43.csv")
true_R1.5_pop50_seed5 <- read.csv("data_pop50_R1.5_g0.15_95.csv")

true_R1.5_pop200_seed1 <- read.csv("data_pop200_R1.5_g0.15_81.csv")
true_R1.5_pop200_seed2 <- read.csv("data_pop200_R1.5_g0.15_93.csv")
true_R1.5_pop200_seed3 <- read.csv("data_pop200_R1.5_g0.15_102.csv")
true_R1.5_pop200_seed4 <- read.csv("data_pop200_R1.5_g0.15_202.csv")
true_R1.5_pop200_seed5 <- read.csv("data_pop200_R1.5_g0.15_246.csv")

true_R1.5_pop1000_seed1 <- read.csv("data_pop1000_R1.5_g0.15_177.csv")
true_R1.5_pop1000_seed2 <- read.csv("data_pop1000_R1.5_g0.15_246.csv")
true_R1.5_pop1000_seed3 <- read.csv("data_pop1000_R1.5_g0.15_469.csv")
true_R1.5_pop1000_seed4 <- read.csv("data_pop1000_R1.5_g0.15_520.csv")
true_R1.5_pop1000_seed5 <- read.csv("data_pop1000_R1.5_g0.15_784.csv")

letter_place = 72 
letter_size = 3
axis_size = 2.5
yaxis_size = 2
number_size = 2

# Plot for SIR model - R0 = 1.5
# plot.new()
par(mfrow = c(3,5), mar=c(5,5,0.2,0.2))
# Pop = 50
N = 50
# Seed 1
plot(x = true_R1.5_pop50_seed1$time, y = true_R1.5_pop50_seed1$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop50_seed1$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop50_seed1$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "A", cex = letter_size)
# Seed 2
plot(x = true_R1.5_pop50_seed2$time, y = true_R1.5_pop50_seed2$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop50_seed2$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop50_seed2$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "B", cex = letter_size)
# Seed 3
plot(x = true_R1.5_pop50_seed3$time, y = true_R1.5_pop50_seed3$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop50_seed3$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop50_seed3$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "C", cex = letter_size)
# Seed 4
plot(x = true_R1.5_pop50_seed4$time, y = true_R1.5_pop50_seed4$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop50_seed4$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop50_seed4$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "D", cex = letter_size)
# Seed 5
plot(x = true_R1.5_pop50_seed5$time, y = true_R1.5_pop50_seed5$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop50_seed5$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop50_seed5$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "E", cex = letter_size)
# Pop = 200
N = 200
# Seed 1
plot(x = true_R1.5_pop200_seed1$time, y = true_R1.5_pop200_seed1$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed1$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop200_seed1$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "F", cex = letter_size)
mtext("Number susceptible/infected/recovered", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 2
plot(x = true_R1.5_pop200_seed2$time, y = true_R1.5_pop200_seed2$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed2$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop200_seed2$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "G", cex = letter_size)
# Seed 3
plot(x = true_R1.5_pop200_seed3$time, y = true_R1.5_pop200_seed3$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed3$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop200_seed3$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "H", cex = letter_size)
# Seed 4
plot(x = true_R1.5_pop200_seed4$time, y = true_R1.5_pop200_seed4$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed4$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop200_seed4$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "I", cex = letter_size)
# Seed 5
plot(x = true_R1.5_pop200_seed5$time, y = true_R1.5_pop200_seed5$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed5$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop200_seed5$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "J", cex = letter_size)
# Pop = 1000
N = 1000
# Seed 1
plot(x = true_R1.5_pop1000_seed1$time, y = true_R1.5_pop1000_seed1$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed1$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop1000_seed1$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "K", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 2
plot(x = true_R1.5_pop1000_seed2$time, y = true_R1.5_pop1000_seed2$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed2$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop1000_seed2$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "L", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 3
plot(x = true_R1.5_pop1000_seed3$time, y = true_R1.5_pop1000_seed3$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed3$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop1000_seed3$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "M", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 4
plot(x = true_R1.5_pop1000_seed4$time, y = true_R1.5_pop1000_seed4$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed4$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop1000_seed4$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "N", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 5
plot(x = true_R1.5_pop1000_seed5$time, y = true_R1.5_pop1000_seed5$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed5$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R1.5_pop1000_seed5$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "O", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
@
\caption{Plots showing how the number of susceptible (black), infectious (red), and recovered (orange) individuals changes with time during an outbreak generated with a stochastic SIR model with an $R_{0}$ of 1.5 and $\gamma$ of 0.15. Plots A-E have a population size of 50, plots F-J have a population size of 200, and plots K-O have a population size of 1000.}
\end{center}
\end{figure}

The shapes of all the outbreaks with an $R_{0}$ of 1.5 are similar, with most outbreaks reaching their peak number of infected individuals at around 20 days (Figure 2). Outbreaks with an $R_{0}$ of 6 had a higher peak in the infectious curve than outbreaks with an $R_{0}$ of 1.5 though the peak is also at around 20 days (Figure 3). The variability in outbreak shape reduces with increasing population size for both outbreak severity.
\newline

\begin{figure}[h]
\begin{center}
<<dataplot2, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, fig.pos="H", height=13, width=17, fig.height=4, fig.lp = "Figure", fig.cap="Data plot", fig=TRUE>>=
# R0 = 6

true_R6_pop50_seed1 <- read.csv("data_pop50_R6_g0.15_1.csv")
true_R6_pop50_seed2 <- read.csv("data_pop50_R6_g0.15_2.csv")
true_R6_pop50_seed3 <- read.csv("data_pop50_R6_g0.15_3.csv")
true_R6_pop50_seed4 <- read.csv("data_pop50_R6_g0.15_4.csv")
true_R6_pop50_seed5 <- read.csv("data_pop50_R6_g0.15_5.csv")

true_R6_pop200_seed1 <- read.csv("data_pop200_R6_g0.15_6.csv")
true_R6_pop200_seed2 <- read.csv("data_pop200_R6_g0.15_7.csv")
true_R6_pop200_seed3 <- read.csv("data_pop200_R6_g0.15_8.csv")
true_R6_pop200_seed4 <- read.csv("data_pop200_R6_g0.15_9.csv")
true_R6_pop200_seed5 <- read.csv("data_pop200_R6_g0.15_10.csv")

true_R6_pop1000_seed1 <- read.csv("data_pop1000_R6_g0.15_11.csv")
true_R6_pop1000_seed2 <- read.csv("data_pop1000_R6_g0.15_12.csv")
true_R6_pop1000_seed3 <- read.csv("data_pop1000_R6_g0.15_13.csv")
true_R6_pop1000_seed4 <- read.csv("data_pop1000_R6_g0.15_14.csv")
true_R6_pop1000_seed5 <- read.csv("data_pop1000_R6_g0.15_15.csv")

letter_place = 72 
letter_size = 3
axis_size = 2.5
yaxis_size = 2
number_size = 2

# Plot for SIR model - R0 = 6
# plot.new()
par(mfrow = c(3,5), mar=c(5,5,0.2,0.2))
# Pop = 50
N = 50
# Seed 1
plot(x = true_R6_pop50_seed1$time, y = true_R6_pop50_seed1$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed1$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop50_seed1$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "A", cex = letter_size)
# Seed 2
plot(x = true_R6_pop50_seed2$time, y = true_R6_pop50_seed2$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed2$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop50_seed2$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "B", cex = letter_size)
# Seed 3
plot(x = true_R6_pop50_seed3$time, y = true_R6_pop50_seed3$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed3$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop50_seed3$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "C", cex = letter_size)
# Seed 4
plot(x = true_R6_pop50_seed4$time, y = true_R6_pop50_seed4$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed4$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop50_seed4$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "D", cex = letter_size)
# Seed 5
plot(x = true_R6_pop50_seed5$time, y = true_R6_pop50_seed5$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed5$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop50_seed5$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "E", cex = letter_size)
# Pop = 200
N = 200
# Seed 1
plot(x = true_R6_pop200_seed1$time, y = true_R6_pop200_seed1$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed1$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop200_seed1$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "F", cex = letter_size)
mtext("Number susceptible/infected/recovered", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 2
plot(x = true_R6_pop200_seed2$time, y = true_R6_pop200_seed2$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed2$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop200_seed2$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "G", cex = letter_size)
# Seed 3
plot(x = true_R6_pop200_seed3$time, y = true_R6_pop200_seed3$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed3$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop200_seed3$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "H", cex = letter_size)
# Seed 4
plot(x = true_R6_pop200_seed4$time, y = true_R6_pop200_seed4$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed4$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop200_seed4$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "I", cex = letter_size)
# Seed 5
plot(x = true_R6_pop200_seed5$time, y = true_R6_pop200_seed5$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed5$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop200_seed5$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "J", cex = letter_size)
# Pop = 1000
N = 1000
# Seed 1
plot(x = true_R6_pop1000_seed1$time, y = true_R6_pop1000_seed1$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed1$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop1000_seed1$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "K", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 2
plot(x = true_R6_pop1000_seed2$time, y = true_R6_pop1000_seed2$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed2$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop1000_seed2$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "L", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 3
plot(x = true_R6_pop1000_seed3$time, y = true_R6_pop1000_seed3$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed3$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop1000_seed3$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "M", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 4
plot(x = true_R6_pop1000_seed4$time, y = true_R6_pop1000_seed4$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed4$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop1000_seed4$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "N", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
# Seed 5
plot(x = true_R6_pop1000_seed5$time, y = true_R6_pop1000_seed5$I, type = "l", col = "red", ylim = c(0,N), xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed5$S, type = "l", ylim = c(0,N)) # susceptible
lines(true_R6_pop1000_seed5$R, type = "l", col = "orange", ylim = c(0,N)) # recovered
text(letter_place, 0.95*N, "O", cex = letter_size)
mtext("Time", 1, line = 3, cex = yaxis_size)
@
\caption{Plots showing how the number of susceptible (black), infectious (red), and recovered (orange) individuals changes with time during an outbreak generated with a stochastic SIR model with an $R_{0}$ of 6 and $\gamma$ of 0.15. Plots A-E have a population size of 50, plots F-J have a population size of 200, and plots K-O have a population size of 1000.}
\end{center}
\end{figure}

Not all simulations resulted in a continued outbreak for the lower $R_{0}$, but went extinct early on. For example, over half of the the simulated outbreaks for population size of 50 and $R_{0}$ of 1.5 resulted in fewer than 10\% of the population (5 individuals) becoming infected (Fig. 4). These non-starters were removed from further analysis as the values of $\beta$ and $\gamma$ would not be interesting to infer from outbreaks that went extinct very early on. Stochastic extinction early on during an outbreak became less common with increasing population size (Fig. 4).

\begin{figure}[h]
\begin{center}
<<outbreakhistogram, cache=TRUE, echo=FALSE, eval=TRUE, dpi=100, height=8, width=6, fig.cap="Data plot", fig=TRUE>>=
par(mfrow = c(3,1), mar=c(5,6.5,0.4,0.2))
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/"

letter_size = 1.5

outbreak_size <- read.csv(paste(dir, "pop50_R1.5_outbreaksize.csv", sep=""))
outbreak_size <- unlist(outbreak_size)
hist(outbreak_size, nclass=30, col = "gray", main="", xlab = "Outbreak size", xlim = c(0, 50), ylim = c(0, 500))
box()
text(0.97*50, 0.92*500, "A", cex = letter_size)


outbreak_size <- read.csv(paste(dir, "pop200_R1.5_outbreaksize.csv", sep=""))
outbreak_size <- unlist(outbreak_size)

hist(outbreak_size, nclass=30, col = "gray", main="", xlab = "Outbreak size", xlim = c(0, 200), ylim = c(0, 80))
box()
text(0.97*200, 0.92*80, "B", cex = letter_size)

outbreak_size <- read.csv(paste(dir, "pop1000_R1.5_outbreaksize.csv", sep=""))
outbreak_size <- unlist(outbreak_size)

hist(outbreak_size, nclass=30, col = "gray", main="", xlab = "Outbreak size", xlim = c(0, 1000), ylim = c(0, 170))
box()
text(0.97*1000, 0.92*170, "C", cex = letter_size)
@
\caption{Histograms showing the distribution of total outbreak sizes for 1000 simulations with an $R_{0}$ of 1.5 and a population size of 50 (A), 200 (B), and 1000 (C).}
\end{center}
\end{figure}

%%%%%%%%%%
\newpage
\subsection{Residual error}

For an $R_{0}$ of 1.5, the difference between the minimum and maximum observed $\beta$ and $\gamma$ values was often wider than the difference for an $R_{0}$ of 6 (Table 1, Table 2). This can also be seen in the exemplifying graphs (Fig. 4), where the infectious and recovery curves for the point estimate and bootstrapped parameter values with the larger $R_{0}$ are more consistent with each other with less variation in the curves amongst $\beta$ and $\gamma$ values obtained through bootstrapping. It also seems that the deterministic infectious curves resulting from the point estimate values of $\beta$ and $\gamma$ consistently result in an underestimation of the peak of the outbreak for the scenarios where $R_{0}$ is 6 (Figure 4D-F). The $\beta$ estimates lower with increasing population size due to $\beta$ referring to the individual-level probability of becoming infected (Table 1). 

\begin{figure}[!h]
\begin{center}
<<dataplot3, cache=TRUE, echo=FALSE, eval=FALSE, dpi=100, height=13, width=17, fig.cap="Data plot", fig=TRUE>>=
# RE example plots
library("deSolve")

true_R1.5_pop50_seed1 <- read.csv("data_pop50_R1.5_g0.15_14.csv")
true_R1.5_pop200_seed1 <- read.csv("data_pop200_R1.5_g0.15_81.csv")
true_R1.5_pop1000_seed1 <- read.csv("data_pop1000_R1.5_g0.15_177.csv")
true_R6_pop50_seed1 <- read.csv("data_pop50_R6_g0.15_2.csv")
true_R6_pop200_seed1 <- read.csv("data_pop200_R6_g0.15_6.csv")
true_R6_pop1000_seed1 <- read.csv("data_pop1000_R6_g0.15_11.csv")

dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
re_R1.5_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_14.csv", sep=""))
re_R1.5_pop200_seed1 <- read.csv(paste(dir,"re_pop200_R1.5_g0.15_81.csv", sep=""))
re_R1.5_pop1000_seed1 <- read.csv(paste(dir,"re_pop1000_R1.5_g0.15_177.csv", sep=""))
re_R6_pop50_seed1 <- read.csv(paste(dir,"re_pop50_R6_g0.15_2.csv", sep=""))
re_R6_pop200_seed1 <- read.csv(paste(dir,"re_pop200_R6_g0.15_6.csv", sep=""))
re_R6_pop1000_seed1 <- read.csv(paste(dir,"re_pop1000_R6_g0.15_11.csv", sep=""))

sir <- function(time, state, param) {
  
  # define model parameters in term of the natural parameters
  beta <- param[1] 
  gamma <- param[2]
  
  with(as.list(c(state, param)), {
    
    dS <- -(beta * S * I) 
    dI <- (beta * S * I) -(gamma * I)
    dR <-  gamma * I
    
    return(list(c(dS, dI, dR)))
  })
}

pre_sir <- function(run_stoch, sse_data){
# Time
timestep <- run_stoch$time[2] - run_stoch$time[1]
end <- max(run_stoch$time)
times <- seq(0, end, by = timestep)

# Initial population: N-1 susceptible, 1 infectious, 0 recovered
init.values = c(
  S = run_stoch$S[1],
  I = run_stoch$I[1],
  R = run_stoch$R[1]
)
N = sum(init.values)

det_sir <- as.data.frame(ode(y = init.values, times = times, func = sir, parms = sse_data[1:2]))
}

letter_size = 3
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2, 3), mar=c(5,6.5,0.4,0.2))
# R = 1.5, Pop = 50
N = 50
plot(true_R1.5_pop50_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
  lines(true_R1.5_pop50_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
  lines(true_R1.5_pop50_seed1$R, ylim = c(0, N), type = "l", col = "orange", lwd = 3)
for (i in 2:nrow(re_R1.5_pop50_seed1)){
  sir_data <- pre_sir(true_R1.5_pop50_seed1, re_R1.5_pop50_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "gray60", xlab = " ", ylab = " ", lwd = 0.5)
  lines(sir_data$R, type = "l", lty = 3, col = "gray85", xlab = " ", ylab = " ", lwd = 0.5)
}
for (i in 1){
  sir_data <- pre_sir(true_R1.5_pop50_seed1, re_R1.5_pop50_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "black", xlab = " ", ylab = " ", lwd = 2)
  lines(sir_data$R, type = "l", lty = 3, col = "black", xlab = " ", ylab = " ", lwd = 2)
}
text(10, 0.95*N, "A", cex = letter_size)
mtext("Number infected/recovered", 2, line = 4, cex = yaxis_size, outer = FALSE)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 1.5, Pop = 200
N = 200
plot(true_R1.5_pop200_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
lines(true_R1.5_pop200_seed1$R, ylim = c(0, N), type = "l", col = "orange", lwd = 3)
for (i in 2:nrow(re_R1.5_pop200_seed1)){
  sir_data <- pre_sir(true_R1.5_pop200_seed1, re_R1.5_pop200_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "gray50", xlab = " ", ylab = " ", lwd = 0.5)
  lines(sir_data$R, type = "l", lty = 3, col = "gray80", xlab = " ", ylab = " ", lwd = 0.5)
}
for (i in 1){
  sir_data <- pre_sir(true_R1.5_pop200_seed1, re_R1.5_pop200_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "black", xlab = " ", ylab = " ", lwd = 2)
  lines(sir_data$R, type = "l", lty = 3, col = "black", xlab = " ", ylab = " ", lwd = 2)
}
text(10, 0.95*N, "B", cex = letter_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 1.5, Pop = 1000
N = 1000
plot(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
lines(true_R1.5_pop1000_seed1$R, ylim = c(0, N), type = "l", col = "orange", lwd = 3)
for (i in 2:nrow(re_R1.5_pop1000_seed1)){
  sir_data <- pre_sir(true_R1.5_pop1000_seed1, re_R1.5_pop1000_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "gray50", xlab = " ", ylab = " ", lwd = 0.5)
  lines(sir_data$R, type = "l", lty = 3, col = "gray80", xlab = " ", ylab = " ", lwd = 0.5)
}
for (i in 1){
  sir_data <- pre_sir(true_R1.5_pop1000_seed1, re_R1.5_pop1000_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "black", xlab = " ", ylab = " ", lwd = 2)
  lines(sir_data$R, type = "l", lty = 3, col = "black", xlab = " ", ylab = " ", lwd = 2)
}
text(10, 0.95*N, "C", cex = letter_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 6, Pop = 50
N = 50
plot(true_R6_pop50_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
lines(true_R6_pop50_seed1$R, ylim = c(0, N), type = "l", col = "orange", lwd = 3)
for (i in 2:nrow(re_R1.5_pop50_seed1)){
  sir_data <- pre_sir(true_R6_pop50_seed1, re_R6_pop50_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "gray50", xlab = " ", ylab = " ", lwd = 0.5)
  lines(sir_data$R, type = "l", lty = 3, col = "gray80", xlab = " ", ylab = " ", lwd = 0.5)
}
for (i in 1){
  sir_data <- pre_sir(true_R6_pop50_seed1, re_R6_pop50_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "black", xlab = " ", ylab = " ", lwd = 2)
  lines(sir_data$R, type = "l", lty = 3, col = "black", xlab = " ", ylab = " ", lwd = 2)
}
text(10, 0.95*N, "D", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
mtext("Number infected/recovered", 2, line = 4, cex = yaxis_size, outer = FALSE)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 6, Pop = 200
N = 200
plot(true_R6_pop200_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
lines(true_R6_pop200_seed1$R, ylim = c(0, N), type = "l", col = "orange", lwd = 3)
for (i in 2:nrow(re_R1.5_pop200_seed1)){
  sir_data <- pre_sir(true_R6_pop200_seed1, re_R6_pop200_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "gray50", xlab = " ", ylab = " ", lwd = 0.5)
  lines(sir_data$R, type = "l", lty = 3, col = "gray80", xlab = " ", ylab = " ", lwd = 0.5)
}
for (i in 1){
  sir_data <- pre_sir(true_R6_pop200_seed1, re_R6_pop200_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "black", xlab = " ", ylab = " ", lwd = 2)
  lines(sir_data$R, type = "l", lty = 3, col = "black", xlab = " ", ylab = " ", lwd = 2)
}
text(10, 0.95*N, "E", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 6, Pop = 1000
N = 1000
plot(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
lines(true_R6_pop1000_seed1$R, ylim = c(0, N), type = "l", col = "orange", lwd = 3)
for (i in 2:nrow(re_R6_pop1000_seed1)){
  sir_data <- pre_sir(true_R6_pop1000_seed1, re_R6_pop1000_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "gray50", xlab = " ", ylab = " ", lwd = 0.5)
  lines(sir_data$R, type = "l", lty = 3, col = "gray80", xlab = " ", ylab = " ", lwd = 0.5)
}
for (i in 1){
  sir_data <- pre_sir(true_R6_pop1000_seed1, re_R6_pop1000_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "black", xlab = " ", ylab = " ", lwd = 2)
  lines(sir_data$R, type = "l", lty = 3, col = "black", xlab = " ", ylab = " ", lwd = 2)
}
text(10, 0.95*N, "F", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
@
\caption{Comparing the true infected and recovered curves to those constructed from the point estimates and bootstrapping of the RE method. The number of individuals in a population infected (red line) or recovered (orange line) in the true dataset. The black lines refer to the deterministic infectious (dashed) and recovered (dotted) curves based on the $\beta$ and $\gamma$ point estimates. The grey lines represent the deterministic infectious (dark grey) and recovered (light grey) curves based on the optimised $\beta$ and $\gamma$ values during the bootstrapping process. Figures A-C and D-F represent outbreaks with an $R_{0}$ of 1.5 and 6, respectively. Figures A and D represent a population size of 50, Figures B and E represent a population size of 200, and figures C and F represent a population size of 1000.}
\end{center}
\end{figure}


<<RE_result_table_50, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table

results_table <- array(NA, dim =c(12,7))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

seed1 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_14.csv", sep=""))
seed2 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_22.csv", sep=""))
seed3 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_40.csv", sep=""))
seed4 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_43.csv", sep=""))
seed5 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_95.csv", sep=""))

results_table[2,1] <- 1
results_table[3,1] <- 2
results_table[4,1] <- 3
results_table[5,1] <- 4
results_table[6,1] <- 5

results_table[8,1] <- 1
results_table[9,1] <- 2
results_table[10,1] <- 3
results_table[11,1] <- 4
results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
results_table[1,2] <- (1.5 * 0.15) / 50
results_table[2,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[2:1001], c(0.025, 0.975))
results_table[2,3] <- intervals[1]
results_table[2,4] <- intervals[2]
results_table[3,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[2:1001], c(0.025, 0.975))
results_table[3,3] <- intervals[1]
results_table[3,4] <- intervals[2]
results_table[4,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[2:1001], c(0.025, 0.975))
results_table[4,3] <- intervals[1]
results_table[4,4] <- intervals[2]
results_table[5,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[2:1001], c(0.025, 0.975))
results_table[5,3] <- intervals[1]
results_table[5,4] <- intervals[2]
results_table[6,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[2:1001], c(0.025, 0.975))
results_table[6,3] <- intervals[1]
results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
results_table[1,5] <- 0.15
results_table[2,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[2:1001], c(0.025, 0.975))
results_table[2,6] <- intervals[1]
results_table[2,7] <- intervals[2]
results_table[3,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[2:1001], c(0.025, 0.975))
results_table[3,6] <- intervals[1]
results_table[3,7] <- intervals[2]
results_table[4,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[2:1001], c(0.025, 0.975))
results_table[4,6] <- intervals[1]
results_table[4,7] <- intervals[2]
results_table[5,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[2:1001], c(0.025, 0.975))
results_table[5,6] <- intervals[1]
results_table[5,7] <- intervals[2]
results_table[6,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[2:1001], c(0.025, 0.975))
results_table[6,6] <- intervals[1]
results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
seed1 <- read.csv(paste(dir, "re_pop50_R6_g0.15_1.csv", sep =""))
seed2 <- read.csv(paste(dir, "re_pop50_R6_g0.15_2.csv", sep =""))
seed3 <- read.csv(paste(dir, "re_pop50_R6_g0.15_3.csv", sep =""))
seed4 <- read.csv(paste(dir, "re_pop50_R6_g0.15_4.csv", sep =""))
seed5 <- read.csv(paste(dir, "re_pop50_R6_g0.15_5.csv", sep =""))

# Pop = 1000, R0 = 6
results_table[7,2] <- (6 * 0.15) / 50
results_table[8,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[2:1001], c(0.025, 0.975))
results_table[8,3] <- intervals[1]
results_table[8,4] <- intervals[2]
results_table[9,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[2:1001], c(0.025, 0.975))
results_table[9,3] <- intervals[1]
results_table[9,4] <- intervals[2]
results_table[10,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[2:1001], c(0.025, 0.975))
results_table[10,3] <- intervals[1]
results_table[10,4] <- intervals[2]
results_table[11,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[2:1001], c(0.025, 0.975))
results_table[11,3] <- intervals[1]
results_table[11,4] <- intervals[2]
results_table[12,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[2:1001], c(0.025, 0.975))
results_table[12,3] <- intervals[1]
results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
results_table[7,5] <- 0.15
results_table[8,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[2:1001], c(0.025, 0.975))
results_table[8,6] <- intervals[1]
results_table[8,7] <- intervals[2]
results_table[9,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[2:1001], c(0.025, 0.975))
results_table[9,6] <- intervals[1]
results_table[9,7] <- intervals[2]
results_table[10,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[2:1001], c(0.025, 0.975))
results_table[10,6] <- intervals[1]
results_table[10,7] <- intervals[2]
results_table[11,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[2:1001], c(0.025, 0.975))
results_table[11,6] <- intervals[1]
results_table[11,7] <- intervals[2]
results_table[12,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[2:1001], c(0.025, 0.975))
results_table[12,6] <- intervals[1]
results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the RE inference method  $R_{0}$ of 1.5 or 6 for a population size of 50. min: lower bound of 95\\% interval, max: upper bound of 95\\% interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

<<RE_result_table_200, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table

results_table <- array(NA, dim =c(12,7))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

seed1 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_81.csv", sep=""))
seed2 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_93.csv", sep=""))
seed3 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_102.csv", sep=""))
seed4 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_202.csv", sep=""))
seed5 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_246.csv", sep=""))

results_table[2,1] <- 1
results_table[3,1] <- 2
results_table[4,1] <- 3
results_table[5,1] <- 4
results_table[6,1] <- 5

results_table[8,1] <- 1
results_table[9,1] <- 2
results_table[10,1] <- 3
results_table[11,1] <- 4
results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
results_table[1,2] <- (1.5 * 0.15) / 200
results_table[2,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[2:1001], c(0.025, 0.975))
results_table[2,3] <- intervals[1]
results_table[2,4] <- intervals[2]
results_table[3,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[2:1001], c(0.025, 0.975))
results_table[3,3] <- intervals[1]
results_table[3,4] <- intervals[2]
results_table[4,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[2:1001], c(0.025, 0.975))
results_table[4,3] <- intervals[1]
results_table[4,4] <- intervals[2]
results_table[5,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[2:1001], c(0.025, 0.975))
results_table[5,3] <- intervals[1]
results_table[5,4] <- intervals[2]
results_table[6,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[2:1001], c(0.025, 0.975))
results_table[6,3] <- intervals[1]
results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
results_table[1,5] <- 0.15
results_table[2,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[2:1001], c(0.025, 0.975))
results_table[2,6] <- intervals[1]
results_table[2,7] <- intervals[2]
results_table[3,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[2:1001], c(0.025, 0.975))
results_table[3,6] <- intervals[1]
results_table[3,7] <- intervals[2]
results_table[4,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[2:1001], c(0.025, 0.975))
results_table[4,6] <- intervals[1]
results_table[4,7] <- intervals[2]
results_table[5,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[2:1001], c(0.025, 0.975))
results_table[5,6] <- intervals[1]
results_table[5,7] <- intervals[2]
results_table[6,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[2:1001], c(0.025, 0.975))
results_table[6,6] <- intervals[1]
results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
seed1 <- read.csv(paste(dir, "re_pop200_R6_g0.15_6.csv", sep =""))
seed2 <- read.csv(paste(dir, "re_pop200_R6_g0.15_7.csv", sep =""))
seed3 <- read.csv(paste(dir, "re_pop200_R6_g0.15_8.csv", sep =""))
seed4 <- read.csv(paste(dir, "re_pop200_R6_g0.15_9.csv", sep =""))
seed5 <- read.csv(paste(dir, "re_pop200_R6_g0.15_10.csv", sep =""))

# Pop = 1000, R0 = 6
results_table[7,2] <- (6 * 0.15) / 200
results_table[8,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[2:1001], c(0.025, 0.975))
results_table[8,3] <- intervals[1]
results_table[8,4] <- intervals[2]
results_table[9,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[2:1001], c(0.025, 0.975))
results_table[9,3] <- intervals[1]
results_table[9,4] <- intervals[2]
results_table[10,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[2:1001], c(0.025, 0.975))
results_table[10,3] <- intervals[1]
results_table[10,4] <- intervals[2]
results_table[11,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[2:1001], c(0.025, 0.975))
results_table[11,3] <- intervals[1]
results_table[11,4] <- intervals[2]
results_table[12,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[2:1001], c(0.025, 0.975))
results_table[12,3] <- intervals[1]
results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
results_table[7,5] <- 0.15
results_table[8,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[2:1001], c(0.025, 0.975))
results_table[8,6] <- intervals[1]
results_table[8,7] <- intervals[2]
results_table[9,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[2:1001], c(0.025, 0.975))
results_table[9,6] <- intervals[1]
results_table[9,7] <- intervals[2]
results_table[10,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[2:1001], c(0.025, 0.975))
results_table[10,6] <- intervals[1]
results_table[10,7] <- intervals[2]
results_table[11,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[2:1001], c(0.025, 0.975))
results_table[11,6] <- intervals[1]
results_table[11,7] <- intervals[2]
results_table[12,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[2:1001], c(0.025, 0.975))
results_table[12,6] <- intervals[1]
results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the RE inference method  $R_{0}$ of 1.5 or 6 for a population size of 200. min: lower bound of 95\\% interval, max: upper bound of 95\\% interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

<<RE_result_table_1000, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table

results_table <- array(NA, dim =c(12,7))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

seed1 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_177.csv", sep=""))
seed2 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_246.csv", sep=""))
seed3 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_469.csv", sep=""))
seed4 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_520.csv", sep=""))
seed5 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_784.csv", sep=""))

results_table[2,1] <- 1
results_table[3,1] <- 2
results_table[4,1] <- 3
results_table[5,1] <- 4
results_table[6,1] <- 5

results_table[8,1] <- 1
results_table[9,1] <- 2
results_table[10,1] <- 3
results_table[11,1] <- 4
results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
results_table[1,2] <- (1.5 * 0.15) / 1000
results_table[2,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[2:1001], c(0.025, 0.975))
results_table[2,3] <- intervals[1]
results_table[2,4] <- intervals[2]
results_table[3,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[2:1001], c(0.025, 0.975))
results_table[3,3] <- intervals[1]
results_table[3,4] <- intervals[2]
results_table[4,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[2:1001], c(0.025, 0.975))
results_table[4,3] <- intervals[1]
results_table[4,4] <- intervals[2]
results_table[5,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[2:1001], c(0.025, 0.975))
results_table[5,3] <- intervals[1]
results_table[5,4] <- intervals[2]
results_table[6,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[2:1001], c(0.025, 0.975))
results_table[6,3] <- intervals[1]
results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
results_table[1,5] <- 0.15
results_table[2,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[2:1001], c(0.025, 0.975))
results_table[2,6] <- intervals[1]
results_table[2,7] <- intervals[2]
results_table[3,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[2:1001], c(0.025, 0.975))
results_table[3,6] <- intervals[1]
results_table[3,7] <- intervals[2]
results_table[4,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[2:1001], c(0.025, 0.975))
results_table[4,6] <- intervals[1]
results_table[4,7] <- intervals[2]
results_table[5,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[2:1001], c(0.025, 0.975))
results_table[5,6] <- intervals[1]
results_table[5,7] <- intervals[2]
results_table[6,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[2:1001], c(0.025, 0.975))
results_table[6,6] <- intervals[1]
results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
seed1 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_11.csv", sep =""))
seed2 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_12.csv", sep =""))
seed3 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_13.csv", sep =""))
seed4 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_14.csv", sep =""))
seed5 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_15.csv", sep =""))

# Pop = 1000, R0 = 6
results_table[7,2] <- (6 * 0.15) / 1000
results_table[8,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[2:1001], c(0.025, 0.975))
results_table[8,3] <- intervals[1]
results_table[8,4] <- intervals[2]
results_table[9,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[2:1001], c(0.025, 0.975))
results_table[9,3] <- intervals[1]
results_table[9,4] <- intervals[2]
results_table[10,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[2:1001], c(0.025, 0.975))
results_table[10,3] <- intervals[1]
results_table[10,4] <- intervals[2]
results_table[11,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[2:1001], c(0.025, 0.975))
results_table[11,3] <- intervals[1]
results_table[11,4] <- intervals[2]
results_table[12,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[2:1001], c(0.025, 0.975))
results_table[12,3] <- intervals[1]
results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
results_table[7,5] <- 0.15
results_table[8,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[2:1001], c(0.025, 0.975))
results_table[8,6] <- intervals[1]
results_table[8,7] <- intervals[2]
results_table[9,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[2:1001], c(0.025, 0.975))
results_table[9,6] <- intervals[1]
results_table[9,7] <- intervals[2]
results_table[10,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[2:1001], c(0.025, 0.975))
results_table[10,6] <- intervals[1]
results_table[10,7] <- intervals[2]
results_table[11,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[2:1001], c(0.025, 0.975))
results_table[11,6] <- intervals[1]
results_table[11,7] <- intervals[2]
results_table[12,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[2:1001], c(0.025, 0.975))
results_table[12,6] <- intervals[1]
results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the RE inference method  $R_{0}$ of 1.5 or 6 for a population size of 1000. min: lower bound of 95\\% interval, max: upper bound of 95\\% interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

% Discarded beta and gamma tables
<<RE_result_table_beta, cache=FALSE, echo=FALSE, eval=FALSE, results=tex>>=
# Making Residual Error table
RE_beta_results_table <- array(NA, dim =c(12,10))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

re_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_14.csv", sep=""))
re_pop50_seed2 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_22.csv", sep=""))
re_pop50_seed3 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_40.csv", sep=""))
re_pop50_seed4 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_43.csv", sep=""))
re_pop50_seed5 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_95.csv", sep=""))
re_pop200_seed1 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_81.csv", sep=""))
re_pop200_seed2 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_93.csv", sep=""))
re_pop200_seed3 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_102.csv", sep=""))
re_pop200_seed4 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_202.csv", sep =""))
re_pop200_seed5 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_246.csv", sep =""))
re_pop1000_seed1 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_177.csv", sep =""))
re_pop1000_seed2 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_246.csv", sep =""))
re_pop1000_seed3 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_469.csv", sep =""))
re_pop1000_seed4 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_520.csv", sep =""))
re_pop1000_seed5 <- read.csv(paste(dir,"re_pop1000_R1.5_g0.15_784.csv", sep =""))

# Pop = 50, R0 = 1.5
RE_beta_results_table[2,1] <- 1
RE_beta_results_table[3,1] <- 2
RE_beta_results_table[4,1] <- 3
RE_beta_results_table[5,1] <- 4
RE_beta_results_table[6,1] <- 5
RE_beta_results_table[1,2] <- (1.5 * 0.15) / 50
RE_beta_results_table[2,2] <- re_pop50_seed1$beta[1]
sorted <- sort(re_pop50_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[2,3] <- sorted[25]
RE_beta_results_table[2,4] <- sorted[975]
RE_beta_results_table[3,2] <- re_pop50_seed2$beta[1]
sorted <- sort(re_pop50_seed2$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[3,3] <- sorted[25]
RE_beta_results_table[3,4] <- sorted[975]
RE_beta_results_table[4,2] <- re_pop50_seed3$beta[1]
sorted <- sort(re_pop50_seed3$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[4,3] <- sorted[25]
RE_beta_results_table[4,4] <- sorted[975]
RE_beta_results_table[5,2] <- re_pop50_seed4$beta[1]
sorted <- sort(re_pop50_seed4$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[5,3] <- sorted[25]
RE_beta_results_table[5,4] <- sorted[975]
RE_beta_results_table[6,2] <- re_pop50_seed5$beta[1]
sorted <- sort(re_pop50_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[6,3] <- sorted[25]
RE_beta_results_table[6,4] <- sorted[975]
# Pop = 200, R0 = 1.5
RE_beta_results_table[1,5] <- (1.5 * 0.15) / 200
RE_beta_results_table[2,5] <- re_pop200_seed1$beta[1]
sorted <- sort(re_pop200_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[2,6] <- sorted[25]
RE_beta_results_table[2,7] <- sorted[975]
RE_beta_results_table[3,5] <- re_pop200_seed2$beta[1]
sorted <- sort(re_pop200_seed2$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[3,6] <- sorted[25]
RE_beta_results_table[3,7] <- sorted[975]
RE_beta_results_table[4,5] <- re_pop200_seed3$beta[1]
sorted <- sort(re_pop200_seed3$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[4,6] <- sorted[25]
RE_beta_results_table[4,7] <- sorted[975]
RE_beta_results_table[5,5] <- re_pop200_seed4$beta[1]
sorted <- sort(re_pop200_seed4$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[5,6] <- sorted[25]
RE_beta_results_table[5,7] <- sorted[975]
RE_beta_results_table[6,5] <- re_pop200_seed5$beta[1]
sorted <- sort(re_pop200_seed5$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[6,6] <- sorted[25]
RE_beta_results_table[6,7] <- sorted[975]
# Pop = 1000, R0 = 1.5
RE_beta_results_table[1,8] <- (1.5 * 0.15) / 1000
RE_beta_results_table[2,8] <- re_pop1000_seed1$beta[1]
sorted <- sort(re_pop1000_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[2,9] <- sorted[25]
RE_beta_results_table[2,10] <- sorted[975]
RE_beta_results_table[3,8] <- re_pop1000_seed2$beta[1]
sorted <- sort(re_pop1000_seed2$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[3,9] <- sorted[25]
RE_beta_results_table[3,10] <- sorted[975]
RE_beta_results_table[4,8] <- re_pop1000_seed3$beta[1]
sorted <- sort(re_pop1000_seed3$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[4,9] <- sorted[25]
RE_beta_results_table[4,10] <- sorted[975]
RE_beta_results_table[5,8] <- re_pop1000_seed4$beta[1]
sorted <- sort(re_pop1000_seed4$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[5,9] <- sorted[25]
RE_beta_results_table[5,10] <- sorted[975]
RE_beta_results_table[6,8] <- re_pop1000_seed5$beta[1]
sorted <- sort(re_pop1000_seed5$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[6,9] <- sorted[25]
RE_beta_results_table[6,10] <- sorted[975]

# R0 = 6 Gamma = 0.15
re_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R6_g0.15_1.csv", sep =""))
re_pop50_seed2 <- read.csv(paste(dir, "re_pop50_R6_g0.15_2.csv", sep =""))
re_pop50_seed3 <- read.csv(paste(dir, "re_pop50_R6_g0.15_3.csv", sep =""))
re_pop50_seed4 <- read.csv(paste(dir, "re_pop50_R6_g0.15_4.csv", sep =""))
re_pop50_seed5 <- read.csv(paste(dir, "re_pop50_R6_g0.15_5.csv", sep =""))
re_pop200_seed1 <- read.csv(paste(dir, "re_pop200_R6_g0.15_6.csv", sep =""))
re_pop200_seed2 <- read.csv(paste(dir, "re_pop200_R6_g0.15_7.csv", sep =""))
re_pop200_seed3 <- read.csv(paste(dir, "re_pop200_R6_g0.15_8.csv", sep =""))
re_pop200_seed4 <- read.csv(paste(dir, "re_pop200_R6_g0.15_9.csv", sep =""))
re_pop200_seed5 <- read.csv(paste(dir, "re_pop200_R6_g0.15_10.csv", sep =""))
re_pop1000_seed1 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_11.csv", sep =""))
re_pop1000_seed2 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_12.csv", sep =""))
re_pop1000_seed3 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_13.csv", sep =""))
re_pop1000_seed4 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_14.csv", sep =""))
re_pop1000_seed5 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_15.csv", sep =""))

# Pop = 50, R0 = 6
RE_beta_results_table[8,1] <- 1
RE_beta_results_table[9,1] <- 2
RE_beta_results_table[10,1] <- 3
RE_beta_results_table[11,1] <- 4
RE_beta_results_table[12,1] <- 5
RE_beta_results_table[7,2] <- (6 * 0.15) / 50
RE_beta_results_table[8,2] <- re_pop50_seed1$beta[1]
sorted <- sort(re_pop50_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[8,3] <- sorted[25]
RE_beta_results_table[8,4] <- sorted[975]
RE_beta_results_table[9,2] <- re_pop50_seed2$beta[1]
sorted <- sort(re_pop50_seed2$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[9,3] <- sorted[25]
RE_beta_results_table[9,4] <- sorted[975]
RE_beta_results_table[10,2] <- re_pop50_seed3$beta[1]
sorted <- sort(re_pop50_seed3$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[10,3] <- sorted[25]
RE_beta_results_table[10,4] <- sorted[975]
RE_beta_results_table[11,2] <- re_pop50_seed4$beta[1]
sorted <- sort(re_pop50_seed4$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[11,3] <- sorted[25]
RE_beta_results_table[11,4] <- sorted[975]
RE_beta_results_table[12,2] <- re_pop50_seed5$beta[1]
sorted <- sort(re_pop50_seed5$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[12,3] <- sorted[25]
RE_beta_results_table[12,4] <- sorted[975]
# Pop = 200, R0 = 6
RE_beta_results_table[7,5] <- (6 * 0.15) / 200
RE_beta_results_table[8,5] <- re_pop200_seed1$beta[1]
sorted <- sort(re_pop200_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[8,6] <- sorted[25]
RE_beta_results_table[8,7] <- sorted[975]
RE_beta_results_table[9,5] <- re_pop200_seed2$beta[1]
sorted <- sort(re_pop200_seed2$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[9,6] <- sorted[25]
RE_beta_results_table[9,7] <- sorted[975]
RE_beta_results_table[10,5] <- re_pop200_seed3$beta[1]
sorted <- sort(re_pop200_seed3$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[10,6] <- sorted[25]
RE_beta_results_table[10,7] <- sorted[975]
RE_beta_results_table[11,5] <- re_pop200_seed4$beta[1]
sorted <- sort(re_pop200_seed4$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[11,6] <- sorted[25]
RE_beta_results_table[11,7] <- sorted[975]
RE_beta_results_table[12,5] <- re_pop200_seed5$beta[1]
sorted <- sort(re_pop200_seed5$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[12,6] <- sorted[25]
RE_beta_results_table[12,7] <- sorted[975]
# Pop = 1000, R0 = 6
RE_beta_results_table[7,8] <- (6 * 0.15) / 1000
RE_beta_results_table[8,8] <- re_pop1000_seed1$beta[1]
sorted <- sort(re_pop1000_seed1$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[8,9] <- sorted[25]
RE_beta_results_table[8,10] <- sorted[975]
RE_beta_results_table[9,8] <- re_pop1000_seed2$beta[1]
sorted <- sort(re_pop1000_seed2$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[9,9] <- sorted[25]
RE_beta_results_table[9,10] <- sorted[975]
RE_beta_results_table[10,8] <- re_pop1000_seed3$beta[1]
sorted <- sort(re_pop1000_seed3$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[10,9] <- sorted[25]
RE_beta_results_table[10,10] <- sorted[975]
RE_beta_results_table[11,8] <- re_pop1000_seed4$beta[1]
sorted <- sort(re_pop1000_seed4$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[11,9] <- sorted[25]
RE_beta_results_table[11,10] <- sorted[975]
RE_beta_results_table[12,8] <- re_pop1000_seed5$beta[1]
sorted <- sort(re_pop1000_seed5$beta[2:1001], decreasing=FALSE)
RE_beta_results_table[12,9] <- sorted[25]
RE_beta_results_table[12,10] <- sorted[975]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(RE_beta_results_table) <- c("1.5", ".", "..", "...", "....", ".....","6", "-", "--", "---", "----", "-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{ }  & \\multicolumn{3}{l}{N = 50}  & \\multicolumn{3}{l}{N = 200} & \\multicolumn{3}{l}{N = 1000} \\\\\n", "$R_{0}$ & sim  & PE & min & max & PE & min & max & PE & min & max \\\\\n")

tab <- xtable(RE_beta_results_table, digits= c(1, 0, -1, -1, -1, -1, -1, -1, -1, -1, -1), table.placement="!h", caption = "$\\beta$ values for the RE inference method for each outbreak of a given population size N and $R_{0}$ of 1.5 or 6. PE: point estimate; min: lower bound of 95\\% interval obtained through bootstrapping, max: upper bound of 95\\% interval obtained through bootstrapping") 
align(tab) <- "lllllllllll"
print(tab, hline.after=c(-1,0,12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@
<<RE_result_table_gamma, cache=FALSE, echo=FALSE, eval=FALSE, results=tex>>=
# Making Residual Error table
RE_results_table <- array(NA, dim =c(12,10))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

re_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_14.csv", sep=""))
re_pop50_seed2 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_22.csv", sep=""))
re_pop50_seed3 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_40.csv", sep=""))
re_pop50_seed4 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_43.csv", sep=""))
re_pop50_seed5 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_95.csv", sep=""))
re_pop200_seed1 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_81.csv", sep=""))
re_pop200_seed2 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_93.csv", sep=""))
re_pop200_seed3 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_102.csv", sep=""))
re_pop200_seed4 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_202.csv", sep =""))
re_pop200_seed5 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_246.csv", sep =""))
re_pop1000_seed1 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_177.csv", sep =""))
re_pop1000_seed2 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_246.csv", sep =""))
re_pop1000_seed3 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_469.csv", sep =""))
re_pop1000_seed4 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_520.csv", sep =""))
re_pop1000_seed5 <- read.csv(paste(dir,"re_pop1000_R1.5_g0.15_784.csv", sep =""))
gamma <- 0.15

# Pop = 50, R0 = 1.5
RE_results_table[1,1] <- 0
RE_results_table[2,1] <- 1
RE_results_table[3,1] <- 2
RE_results_table[4,1] <- 3
RE_results_table[5,1] <- 4
RE_results_table[6,1] <- 5
RE_results_table[1,2] <- gamma
RE_results_table[2,2] <- re_pop50_seed1$gamma[1]
sorted <- sort(re_pop50_seed1$gamma[2:1001], decreasing=FALSE)
RE_results_table[2,3] <- sorted[25]
RE_results_table[2,4] <- sorted[975]
RE_results_table[3,2] <- re_pop50_seed2$gamma[1]
sorted <- sort(re_pop50_seed2$gamma[2:1001], decreasing=FALSE)
RE_results_table[3,3] <- sorted[25]
RE_results_table[3,4] <- sorted[975]
RE_results_table[4,2] <- re_pop50_seed3$gamma[1]
sorted <- sort(re_pop50_seed3$gamma[2:1001], decreasing=FALSE)
RE_results_table[4,3] <- sorted[25]
RE_results_table[4,4] <- sorted[975]
RE_results_table[5,2] <- re_pop50_seed4$gamma[1]
sorted <- sort(re_pop50_seed4$gamma[2:1001], decreasing=FALSE)
RE_results_table[5,3] <- sorted[25]
RE_results_table[5,4] <- sorted[975]
RE_results_table[6,2] <- re_pop50_seed5$gamma[1]
sorted <- sort(re_pop50_seed5$gamma[2:1001], decreasing=FALSE)
RE_results_table[6,3] <- sorted[25]
RE_results_table[6,4] <- sorted[975]
# Pop = 200, R0 = 1.5
RE_results_table[1,5] <- gamma
RE_results_table[2,5] <- re_pop200_seed1$gamma[1]
sorted <- sort(re_pop200_seed1$gamma[2:1001], decreasing=FALSE)
RE_results_table[2,6] <- sorted[25]
RE_results_table[2,7] <- sorted[975]
RE_results_table[3,5] <- re_pop200_seed2$gamma[1]
sorted <- sort(re_pop200_seed2$gamma[2:1001], decreasing=FALSE)
RE_results_table[3,6] <- sorted[25]
RE_results_table[3,7] <- sorted[975]
RE_results_table[4,5] <- re_pop200_seed3$gamma[1]
sorted <- sort(re_pop200_seed3$gamma[2:1001], decreasing=FALSE)
RE_results_table[4,6] <- sorted[25]
RE_results_table[4,7] <- sorted[975]
RE_results_table[5,5] <- re_pop200_seed4$gamma[1]
sorted <- sort(re_pop200_seed4$gamma[2:1001], decreasing=FALSE)
RE_results_table[5,6] <- sorted[25]
RE_results_table[5,7] <- sorted[975]
RE_results_table[6,5] <- re_pop200_seed5$gamma[1]
sorted <- sort(re_pop200_seed5$gamma[2:1001], decreasing=FALSE)
RE_results_table[6,6] <- sorted[25]
RE_results_table[6,7] <- sorted[975]
# Pop = 1000, R0 = 1.5
RE_results_table[1,8] <- gamma
RE_results_table[2,8] <- re_pop1000_seed1$gamma[1]
sorted <- sort(re_pop1000_seed1$gamma[2:1001], decreasing=FALSE)
RE_results_table[2,9] <- sorted[25]
RE_results_table[2,10] <- sorted[975]
RE_results_table[3,8] <- re_pop1000_seed2$gamma[1]
sorted <- sort(re_pop1000_seed2$gamma[2:1001], decreasing=FALSE)
RE_results_table[3,9] <- sorted[25]
RE_results_table[3,10] <- sorted[975]
RE_results_table[4,8] <- re_pop1000_seed3$gamma[1]
sorted <- sort(re_pop1000_seed3$gamma[2:1001], decreasing=FALSE)
RE_results_table[4,9] <- sorted[25]
RE_results_table[4,10] <- sorted[975]
RE_results_table[5,8] <- re_pop1000_seed4$gamma[1]
sorted <- sort(re_pop1000_seed4$gamma[2:1001], decreasing=FALSE)
RE_results_table[5,9] <- sorted[25]
RE_results_table[5,10] <- sorted[975]
RE_results_table[6,8] <- re_pop1000_seed5$gamma[1]
sorted <- sort(re_pop1000_seed5$gamma[2:1001], decreasing=FALSE)
RE_results_table[6,9] <- sorted[25]
RE_results_table[6,10] <- sorted[975]

# R0 = 6 Gamma = 0.15
re_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R6_g0.15_1.csv", sep =""))
re_pop50_seed2 <- read.csv(paste(dir, "re_pop50_R6_g0.15_2.csv", sep =""))
re_pop50_seed3 <- read.csv(paste(dir, "re_pop50_R6_g0.15_3.csv", sep =""))
re_pop50_seed4 <- read.csv(paste(dir, "re_pop50_R6_g0.15_4.csv", sep =""))
re_pop50_seed5 <- read.csv(paste(dir, "re_pop50_R6_g0.15_5.csv", sep =""))
re_pop200_seed1 <- read.csv(paste(dir, "re_pop200_R6_g0.15_6.csv", sep =""))
re_pop200_seed2 <- read.csv(paste(dir, "re_pop200_R6_g0.15_7.csv", sep =""))
re_pop200_seed3 <- read.csv(paste(dir, "re_pop200_R6_g0.15_8.csv", sep =""))
re_pop200_seed4 <- read.csv(paste(dir, "re_pop200_R6_g0.15_9.csv", sep =""))
re_pop200_seed5 <- read.csv(paste(dir, "re_pop200_R6_g0.15_10.csv", sep =""))
re_pop1000_seed1 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_11.csv", sep =""))
re_pop1000_seed2 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_12.csv", sep =""))
re_pop1000_seed3 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_13.csv", sep =""))
re_pop1000_seed4 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_14.csv", sep =""))
re_pop1000_seed5 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_15.csv", sep =""))

# Pop = 50, R0 = 6
RE_results_table[7,1] <- 0
RE_results_table[8,1] <- 1
RE_results_table[9,1] <- 2
RE_results_table[10,1] <- 3
RE_results_table[11,1] <- 4
RE_results_table[12,1] <- 5
RE_results_table[7,2] <- gamma
RE_results_table[8,2] <- re_pop50_seed1$gamma[1]
sorted <- sort(re_pop50_seed1$gamma[2:1001], decreasing=FALSE)
RE_results_table[8,3] <- sorted[25]
RE_results_table[8,4] <- sorted[975]
RE_results_table[9,2] <- re_pop50_seed2$gamma[1]
sorted <- sort(re_pop50_seed2$gamma[2:1001], decreasing=FALSE)
RE_results_table[9,3] <- sorted[25]
RE_results_table[9,4] <- sorted[975]
RE_results_table[10,2] <- re_pop50_seed3$gamma[1]
sorted <- sort(re_pop50_seed3$gamma[2:1001], decreasing=FALSE)
RE_results_table[10,3] <- sorted[25]
RE_results_table[10,4] <- sorted[975]
RE_results_table[11,2] <- re_pop50_seed4$gamma[1]
sorted <- sort(re_pop50_seed4$gamma[2:1001], decreasing=FALSE)
RE_results_table[11,3] <- sorted[25]
RE_results_table[11,4] <- sorted[975]
RE_results_table[12,2] <- re_pop50_seed5$gamma[1]
sorted <- sort(re_pop50_seed5$gamma[2:1001], decreasing=FALSE)
RE_results_table[12,3] <- sorted[25]
RE_results_table[12,4] <- sorted[975]
# Pop = 200, R0 = 1.5
RE_results_table[7,5] <- gamma
RE_results_table[8,5] <- re_pop200_seed1$gamma[1]
sorted <- sort(re_pop200_seed1$gamma[2:1001], decreasing=FALSE)
RE_results_table[8,6] <- sorted[25]
RE_results_table[8,7] <- sorted[975]
RE_results_table[9,5] <- re_pop200_seed2$gamma[1]
sorted <- sort(re_pop200_seed2$gamma[2:1001], decreasing=FALSE)
RE_results_table[9,6] <- sorted[25]
RE_results_table[9,7] <- sorted[975]
RE_results_table[10,5] <- re_pop200_seed3$gamma[1]
sorted <- sort(re_pop200_seed3$gamma[2:1001], decreasing=FALSE)
RE_results_table[10,6] <- sorted[25]
RE_results_table[10,7] <- sorted[975]
RE_results_table[11,5] <- re_pop200_seed4$gamma[1]
sorted <- sort(re_pop200_seed4$gamma[2:1001], decreasing=FALSE)
RE_results_table[11,6] <- sorted[25]
RE_results_table[11,7] <- sorted[975]
RE_results_table[12,5] <- re_pop200_seed5$gamma[1]
sorted <- sort(re_pop200_seed5$gamma[2:1001], decreasing=FALSE)
RE_results_table[12,6] <- sorted[25]
RE_results_table[12,7] <- sorted[975]
# Pop = 1000, R0 = 1.5
RE_results_table[7,8] <- gamma
RE_results_table[8,8] <- re_pop1000_seed1$gamma[1]
sorted <- sort(re_pop1000_seed1$gamma[2:1001], decreasing=FALSE)
RE_results_table[8,9] <- sorted[25]
RE_results_table[8,10] <- sorted[975]
RE_results_table[9,8] <- re_pop1000_seed2$gamma[1]
sorted <- sort(re_pop1000_seed2$gamma[2:1001], decreasing=FALSE)
RE_results_table[9,9] <- sorted[25]
RE_results_table[9,10] <- sorted[975]
RE_results_table[10,8] <- re_pop1000_seed3$gamma[1]
sorted <- sort(re_pop1000_seed3$gamma[2:1001], decreasing=FALSE)
RE_results_table[10,9] <- sorted[25]
RE_results_table[10,10] <- sorted[975]
RE_results_table[11,8] <- re_pop1000_seed4$gamma[1]
sorted <- sort(re_pop1000_seed4$gamma[2:1001], decreasing=FALSE)
RE_results_table[11,9] <- sorted[25]
RE_results_table[11,10] <- sorted[975]
RE_results_table[12,8] <- re_pop1000_seed5$gamma[1]
sorted <- sort(re_pop1000_seed5$gamma[2:1001], decreasing=FALSE)
RE_results_table[12,9] <- sorted[25]
RE_results_table[12,10] <- sorted[975]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(RE_results_table) <- c("1.5", ".","..","...","....", ".....","6","-","--","---","----", "-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{c}{ }  & \\multicolumn{3}{l}{N = 50}  & \\multicolumn{3}{l}{N = 200} & \\multicolumn{3}{l}{N = 1000} \\\\\n", "$R_{0}$ & sim & PE & min & max & PE & min & max & PE & min & max \\\\\n")

tab <- xtable(RE_results_table, table.placement="H", digits = c(1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2), caption = "$\\gamma$ values for the RE inference method for each outbreak of a given population size N and $R_{0}$ of 1.5 or 6. PE: point estimate; min: minimum value obtained through bootstrapping, max: maximum obtained through bootstrapping") 

align(tab) <- "lllllllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

Table 1 shows that when comparing the output of the residual error method to the parameter values used to generate the simulations that the RE method was being fit to, it can be seen that the residual error method consistently overestimates the values that $\beta$ might take for all population sizes when $R_{0}$ is 1.5 and consistently underestimates $\beta$ values when $R_{0}$ is 6.

The inferred values of $\gamma$, on the other hand, include the true value used for the generating the simulations more often than with $\beta$, though levels of success vary with $R_{0}$ and population size (Table 2). When $R_{0}$ is 6, the inferred 95\% interval for $\gamma$ includes the true value of 0.15 for all five simulations for the population size of 1000, and twice respectively for the population sizes of 50 and 200 (Table 2). For the smaller $R_{0}$ of 1.5, the true $\gamma$ value is included in the 95\% interval three times for the population size of 1000, once for the 200 member population, and zero times for the population size of 50 (Table 2). Whether the $\gamma$ ranges that did not include the true $\gamma$ value are over- or underestimating can vary even within a given $R_{0}$ and population size. For the population size of 50 for both $R_{0}$s, the 95\% intervals both over- and underestimate the ranges of values $\gamma$ may take. For the population size of 200, $\gamma$ is always overestimated when $R_{0}$ is 6, but is both over- and underestimated when $R_{0}$ is 1.5. When $R_{0}$ is 1.5 and the population size is 1000, the $\gamma$ values are overestimated.   

The heatmap in Figure X shows the REs for different combinations of $\beta$ and $\gamma$ when optimising to the recovery curve of simulation 1 with population size 200 and $R_{0}$ of 1.5. The trend suggests that $\beta$ and $\gamma$ are positively correlated, implying that the REs are remain lower as $\beta$ and $\gamma$. Similar trends in the relationship between $\beta$ and $\gamma$ are observed for the other 29 outbreaks.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.4\textwidth]{heatmap_writeup}
\caption{Heatmap showing squared error for different $\beta$ and $\gamma$ combinations}
\end{center}
\end{figure}
<<heatmap, cache=TRUE, echo=FALSE, eval=FALSE, dpi=100, height=13, width=17, fig.cap="Data plot", fig=TRUE>>=
library("plotly") #package for solving differential equations

dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/"

heatmap <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_81_heatmap.csv", sep=""))
for (i in 1:nrow(heatmap)){
  if (heatmap[i,3] > 5000){
    heatmap[i,3] = 5000
  }
}

matrix_heatmap <- xtabs(RE~beta+gamma, data=heatmap)

beta <- seq(min(heatmap$beta), max(heatmap$beta), by = ((max(heatmap$beta)-min(heatmap$beta))/nrow(matrix_heatmap)))
gamma <- seq(min(heatmap$gamma), max(heatmap$gamma), by = ((max(heatmap$gamma)-min(heatmap$gamma))/nrow(matrix_heatmap)))

tick_beta <- list(
  autotick = FALSE,
  ticks = "outside",
  tick0 = min(heatmap$beta),
  dtick = ((max(heatmap$beta)-min(heatmap$beta))/nrow(matrix_heatmap)),
  ticklen = 5,
  tickwidth = 2,
  tickcolor = toRGB("blue")
)

tick_gamma <- list(
  autotick = FALSE,
  ticks = "outside",
  tick0 = min(heatmap$gamma),
  dtick = ((max(heatmap$gamma)-min(heatmap$gamma))/nrow(matrix_heatmap)),
  tickangle = 45,
  ticklen = 5,
  tickwidth = 2,
  tickcolor = toRGB("blue")
)

m <- list(
  l = 100,
  r = 5,
  b = 80,
  t = 5,
  pad = 4
)

plot_heatmap <- plot_ly(z = matrix_heatmap, x = ~gamma, y = ~beta, colors = colorRamp(c("yellow","darkorange2","orangered","red","maroon","magenta4","blue", "navy", "midnightblue")), type = "heatmap") %>%
  layout(xaxis = tick_gamma, yaxis = tick_beta, margin = m)
# plot_heatmap
heatmap_png <- export(plot_heatmap, file = "plot_heatmap.png")
heatmap_png
@

The sum of squared differences between the model and the true recovery curve increases with population size (Table 3). Additionally, the sum of squared differences for the point estimates tend to be lower for the higher $R_{0}$ than the lower $R_{0}$ for the populations (Table 3). 

<<RE_result_table_RE, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making Residual Error table
RE_results_table <- array(NA, dim =c(10,5))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

re_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_14.csv", sep=""))
re_pop50_seed2 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_22.csv", sep=""))
re_pop50_seed3 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_40.csv", sep=""))
re_pop50_seed4 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_43.csv", sep=""))
re_pop50_seed5 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_95.csv", sep=""))
re_pop200_seed1 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_81.csv", sep=""))
re_pop200_seed2 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_93.csv", sep=""))
re_pop200_seed3 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_102.csv", sep=""))
re_pop200_seed4 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_202.csv", sep =""))
re_pop200_seed5 <- read.csv(paste(dir, "re_pop200_R1.5_g0.15_246.csv", sep =""))
re_pop1000_seed1 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_177.csv", sep =""))
re_pop1000_seed2 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_246.csv", sep =""))
re_pop1000_seed3 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_469.csv", sep =""))
re_pop1000_seed4 <- read.csv(paste(dir, "re_pop1000_R1.5_g0.15_520.csv", sep =""))
re_pop1000_seed5 <- read.csv(paste(dir,"re_pop1000_R1.5_g0.15_784.csv", sep =""))

# Pop = 50, R0 = 1.5
RE_results_table[1,1] <- 1
RE_results_table[2,1] <- 2
RE_results_table[3,1] <- 3
RE_results_table[4,1] <- 4
RE_results_table[5,1] <- 5
RE_results_table[1,2] <- re_pop50_seed1$RE[1]
RE_results_table[2,2] <- re_pop50_seed2$RE[1]
RE_results_table[3,2] <- re_pop50_seed3$RE[1]
RE_results_table[4,2] <- re_pop50_seed4$RE[1]
RE_results_table[5,2] <- re_pop50_seed5$RE[1]
# Pop = 200, R0 = 1.5
RE_results_table[1,3] <- re_pop200_seed1$RE[1]
RE_results_table[2,3] <- re_pop200_seed2$RE[1]
RE_results_table[3,3] <- re_pop200_seed3$RE[1]
RE_results_table[4,3] <- re_pop200_seed4$RE[1]
RE_results_table[5,3] <- re_pop200_seed5$RE[1]
# Pop = 1000, R0 = 1.5
RE_results_table[1,4] <- re_pop1000_seed1$RE[1]
RE_results_table[2,4] <- re_pop1000_seed2$RE[1]
RE_results_table[3,4] <- re_pop1000_seed3$RE[1]
RE_results_table[4,4] <- re_pop1000_seed4$RE[1]
RE_results_table[5,4] <- re_pop1000_seed5$RE[1]

# R0 = 6 Gamma = 0.15
re_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R6_g0.15_1.csv", sep =""))
re_pop50_seed2 <- read.csv(paste(dir, "re_pop50_R6_g0.15_2.csv", sep =""))
re_pop50_seed3 <- read.csv(paste(dir, "re_pop50_R6_g0.15_3.csv", sep =""))
re_pop50_seed4 <- read.csv(paste(dir, "re_pop50_R6_g0.15_4.csv", sep =""))
re_pop50_seed5 <- read.csv(paste(dir, "re_pop50_R6_g0.15_5.csv", sep =""))
re_pop200_seed1 <- read.csv(paste(dir, "re_pop200_R6_g0.15_6.csv", sep =""))
re_pop200_seed2 <- read.csv(paste(dir, "re_pop200_R6_g0.15_7.csv", sep =""))
re_pop200_seed3 <- read.csv(paste(dir, "re_pop200_R6_g0.15_8.csv", sep =""))
re_pop200_seed4 <- read.csv(paste(dir, "re_pop200_R6_g0.15_9.csv", sep =""))
re_pop200_seed5 <- read.csv(paste(dir, "re_pop200_R6_g0.15_10.csv", sep =""))
re_pop1000_seed1 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_11.csv", sep =""))
re_pop1000_seed2 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_12.csv", sep =""))
re_pop1000_seed3 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_13.csv", sep =""))
re_pop1000_seed4 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_14.csv", sep =""))
re_pop1000_seed5 <- read.csv(paste(dir, "re_pop1000_R6_g0.15_15.csv", sep =""))

RE_results_table[6,1] <- 1
RE_results_table[7,1] <- 2
RE_results_table[8,1] <- 3
RE_results_table[9,1] <- 4
RE_results_table[10,1] <- 5
# Pop = 50, R0 = 1.5
RE_results_table[6,2] <- re_pop50_seed1$RE[1]
RE_results_table[7,2] <- re_pop50_seed2$RE[1]
RE_results_table[8,2] <- re_pop50_seed3$RE[1]
RE_results_table[9,2] <- re_pop50_seed4$RE[1]
RE_results_table[10,2] <- re_pop50_seed5$RE[1]
# Pop = 200, R0 = 1.5
RE_results_table[6,3] <- re_pop200_seed1$RE[1]
RE_results_table[7,3] <- re_pop200_seed2$RE[1]
RE_results_table[8,3] <- re_pop200_seed3$RE[1]
RE_results_table[9,3] <- re_pop200_seed4$RE[1]
RE_results_table[10,3] <- re_pop200_seed5$RE[1]
# Pop = 1000, R0 = 1.5
RE_results_table[6,4] <- re_pop1000_seed1$RE[1]
RE_results_table[7,4] <- re_pop1000_seed2$RE[1]
RE_results_table[8,4] <- re_pop1000_seed3$RE[1]
RE_results_table[9,4] <- re_pop1000_seed4$RE[1]
RE_results_table[10,4] <- re_pop1000_seed5$RE[1]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(RE_results_table) <- c("1.5", ".","..","...","....","6","-","--","---","----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{c}{}  & \\multicolumn{1}{c}{N = 50}  & \\multicolumn{1}{c}{N = 200} & \\multicolumn{1}{c}{N = 1000} \\\\\n", "$R_{0}$ & sim & PE & PE & PE \\\\\n")

tab <- xtable(RE_results_table, digits = 0, caption = "Residual error values for the RE inference method for each outbreak of a given population size N and R0 of 1.5 or 6. P.E.: point estimate; min: minimum value obtained through bootstrapping, max: maximum obtained through bootstrapping") 
align(tab) <- "llllll"
print(tab, hline.after=c(-1, 0, 10), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

%%%%%%%%%%

\newpage
\subsection{Markov Chain Monte Carlo}

A MCMC approach was also taken to infer the values that $\beta$ and $\gamma$ might take when given the recovery curve from the simulated outbreak. The MCMC with 3.5 million iterations took between 20 and 25 hours to run to completion while the MCMC with 17.5 iterations took over 120 hours (5 days) to run to completion.

The 95\% credible interval for $\beta$ for the 3.5 million iteration MCMC runs includes the true value for all outbreak simulations in all cases excepting for three outbreaks in the combination of population size 1000 and $R_{0}$ of 6 (Table 4). For $R_{0}$ of 1.5 and population size 50 and 200, the mean of the post-burn-in $\beta$ values is above the true number. For the same $R_{0}$ and a population size of 1000, the mean is either equal to, or slightly less than the true value. For outbreaks where $R_{0}$ is 6 and the population size is 50 and 200, the post-burn-in mean is on either side of the true value, while for a population size of 1000, the mean is consistently below the true value of 0.00090.

<<MCMC_result_table_50, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table
burnIn <- 3500 * 0.23
results_table <- array(NA, dim =c(12,7))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
seed2 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_22_loglik.csv", sep=""))
seed3 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_40_loglik.csv", sep=""))
seed4 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_43_loglik.csv", sep=""))
seed5 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_95_loglik.csv", sep=""))

# results_table[1,1] <- "ref"
results_table[2,1] <- 1
results_table[3,1] <- 2
results_table[4,1] <- 3
results_table[5,1] <- 4
results_table[6,1] <- 5

# results_table[7,1] <- "ref"
results_table[8,1] <- 1
results_table[9,1] <- 2
results_table[10,1] <- 3
results_table[11,1] <- 4
results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
results_table[1,2] <- (1.5 * 0.15) / 50
results_table[2,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[2,3] <- intervals[1]
results_table[2,4] <- intervals[2]
results_table[3,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[3,3] <- intervals[1]
results_table[3,4] <- intervals[2]
results_table[4,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[4,3] <- intervals[1]
results_table[4,4] <- intervals[2]
results_table[5,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[5,3] <- intervals[1]
results_table[5,4] <- intervals[2]
results_table[6,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[6,3] <- intervals[1]
results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
results_table[1,5] <- 0.15
results_table[2,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[2,6] <- intervals[1]
results_table[2,7] <- intervals[2]
results_table[3,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[3,6] <- intervals[1]
results_table[3,7] <- intervals[2]
results_table[4,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[4,6] <- intervals[1]
results_table[4,7] <- intervals[2]
results_table[5,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[5,6] <- intervals[1]
results_table[5,7] <- intervals[2]
results_table[6,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[6,6] <- intervals[1]
results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
seed1 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_1_loglik.csv", sep =""))
seed2 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_2_loglik.csv", sep =""))
seed3 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_3_loglik.csv", sep =""))
seed4 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_4_loglik.csv", sep =""))
seed5 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_5_loglik.csv", sep =""))

# Pop = 1000, R0 = 6
results_table[7,2] <- (6 * 0.15) / 50
results_table[8,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[8,3] <- intervals[1]
results_table[8,4] <- intervals[2]
results_table[9,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[9,3] <- intervals[1]
results_table[9,4] <- intervals[2]
results_table[10,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[10,3] <- intervals[1]
results_table[10,4] <- intervals[2]
results_table[11,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[11,3] <- intervals[1]
results_table[11,4] <- intervals[2]
results_table[12,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[12,3] <- intervals[1]
results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
results_table[7,5] <- 0.15
results_table[8,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[8,6] <- intervals[1]
results_table[8,7] <- intervals[2]
results_table[9,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[9,6] <- intervals[1]
results_table[9,7] <- intervals[2]
results_table[10,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[10,6] <- intervals[1]
results_table[10,7] <- intervals[2]
results_table[11,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[11,6] <- intervals[1]
results_table[11,7] <- intervals[2]
results_table[12,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[12,6] <- intervals[1]
results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the 3.5 million iteration MCMC inference method  $R_{0}$ of 1.5 or 6 for a population size of 50. min: lower bound of 95\\% credible interval, max: upper bound of 95\\% cedible interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

<<MCMC_result_table_200, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table
burnIn <- 3500 * 0.23
results_table <- array(NA, dim =c(12,7))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

seed1 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
seed2 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_93_loglik.csv", sep=""))
seed3 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_102_loglik.csv", sep=""))
seed4 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_202_loglik.csv", sep=""))
seed5 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_246_loglik.csv", sep=""))

# results_table[1,1] <- "ref"
results_table[2,1] <- 1
results_table[3,1] <- 2
results_table[4,1] <- 3
results_table[5,1] <- 4
results_table[6,1] <- 5

# results_table[7,1] <- "ref"
results_table[8,1] <- 1
results_table[9,1] <- 2
results_table[10,1] <- 3
results_table[11,1] <- 4
results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
results_table[1,2] <- (1.5 * 0.15) / 200
results_table[2,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[2,3] <- intervals[1]
results_table[2,4] <- intervals[2]
results_table[3,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[3,3] <- intervals[1]
results_table[3,4] <- intervals[2]
results_table[4,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[4,3] <- intervals[1]
results_table[4,4] <- intervals[2]
results_table[5,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[5,3] <- intervals[1]
results_table[5,4] <- intervals[2]
results_table[6,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[6,3] <- intervals[1]
results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
results_table[1,5] <- 0.15
results_table[2,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[2,6] <- intervals[1]
results_table[2,7] <- intervals[2]
results_table[3,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[3,6] <- intervals[1]
results_table[3,7] <- intervals[2]
results_table[4,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[4,6] <- intervals[1]
results_table[4,7] <- intervals[2]
results_table[5,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[5,6] <- intervals[1]
results_table[5,7] <- intervals[2]
results_table[6,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[6,6] <- intervals[1]
results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
seed1 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_6_loglik.csv", sep =""))
seed2 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_7_loglik.csv", sep =""))
seed3 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_8_loglik.csv", sep =""))
seed4 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_9_loglik.csv", sep =""))
seed5 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_10_loglik.csv", sep =""))

# Pop = 1000, R0 = 6
results_table[7,2] <- (6 * 0.15) / 200
results_table[8,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[8,3] <- intervals[1]
results_table[8,4] <- intervals[2]
results_table[9,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[9,3] <- intervals[1]
results_table[9,4] <- intervals[2]
results_table[10,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[10,3] <- intervals[1]
results_table[10,4] <- intervals[2]
results_table[11,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[11,3] <- intervals[1]
results_table[11,4] <- intervals[2]
results_table[12,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[12,3] <- intervals[1]
results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
results_table[7,5] <- 0.15
results_table[8,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[8,6] <- intervals[1]
results_table[8,7] <- intervals[2]
results_table[9,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[9,6] <- intervals[1]
results_table[9,7] <- intervals[2]
results_table[10,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[10,6] <- intervals[1]
results_table[10,7] <- intervals[2]
results_table[11,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[11,6] <- intervals[1]
results_table[11,7] <- intervals[2]
results_table[12,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[12,6] <- intervals[1]
results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the 3.5 million iteration MCMC inference method  $R_{0}$ of 1.5 or 6 for a population size of 200. min: lower bound of 95\\% credible interval, max: upper bound of 95\\% cedible interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

<<MCMC_result_table_1000, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table
burnIn <- 3500 * 0.23
results_table <- array(NA, dim =c(12,7))

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

seed1 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
seed2 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_246_loglik.csv", sep=""))
seed3 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_469_loglik.csv", sep=""))
seed4 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_520_loglik.csv", sep=""))
seed5 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_784_loglik.csv", sep=""))

# results_table[1,1] <- "ref"
results_table[2,1] <- 1
results_table[3,1] <- 2
results_table[4,1] <- 3
results_table[5,1] <- 4
results_table[6,1] <- 5

# results_table[7,1] <- "ref"
results_table[8,1] <- 1
results_table[9,1] <- 2
results_table[10,1] <- 3
results_table[11,1] <- 4
results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
results_table[1,2] <- (1.5 * 0.15) / 1000
results_table[2,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[2,3] <- intervals[1]
results_table[2,4] <- intervals[2]
results_table[3,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[3,3] <- intervals[1]
results_table[3,4] <- intervals[2]
results_table[4,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[4,3] <- intervals[1]
results_table[4,4] <- intervals[2]
results_table[5,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[5,3] <- intervals[1]
results_table[5,4] <- intervals[2]
results_table[6,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[6,3] <- intervals[1]
results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
results_table[1,5] <- 0.15
results_table[2,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[2,6] <- intervals[1]
results_table[2,7] <- intervals[2]
results_table[3,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[3,6] <- intervals[1]
results_table[3,7] <- intervals[2]
results_table[4,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[4,6] <- intervals[1]
results_table[4,7] <- intervals[2]
results_table[5,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[5,6] <- intervals[1]
results_table[5,7] <- intervals[2]
results_table[6,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[6,6] <- intervals[1]
results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
seed1 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_11_loglik.csv", sep =""))
seed2 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_12_loglik.csv", sep =""))
seed3 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_13_loglik.csv", sep =""))
seed4 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_14_loglik.csv", sep =""))
seed5 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_15_loglik.csv", sep =""))

# Pop = 1000, R0 = 6
results_table[7,2] <- (6 * 0.15) / 1000
results_table[8,2] <- seed1$beta[1]
intervals <- quantile(seed1$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[8,3] <- intervals[1]
results_table[8,4] <- intervals[2]
results_table[9,2] <- seed2$beta[1]
intervals <- quantile(seed2$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[9,3] <- intervals[1]
results_table[9,4] <- intervals[2]
results_table[10,2] <- seed3$beta[1]
intervals <- quantile(seed3$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[10,3] <- intervals[1]
results_table[10,4] <- intervals[2]
results_table[11,2] <- seed4$beta[1]
intervals <- quantile(seed4$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[11,3] <- intervals[1]
results_table[11,4] <- intervals[2]
results_table[12,2] <- seed5$beta[1]
intervals <- quantile(seed5$beta[-(1:burnIn)], c(0.025, 0.975))
results_table[12,3] <- intervals[1]
results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
results_table[7,5] <- 0.15
results_table[8,5] <- seed1$gamma[1]
intervals <- quantile(seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[8,6] <- intervals[1]
results_table[8,7] <- intervals[2]
results_table[9,5] <- seed2$gamma[1]
intervals <- quantile(seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[9,6] <- intervals[1]
results_table[9,7] <- intervals[2]
results_table[10,5] <- seed3$gamma[1]
intervals <- quantile(seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[10,6] <- intervals[1]
results_table[10,7] <- intervals[2]
results_table[11,5] <- seed4$gamma[1]
intervals <- quantile(seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[11,6] <- intervals[1]
results_table[11,7] <- intervals[2]
results_table[12,5] <- seed5$gamma[1]
intervals <- quantile(seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
results_table[12,6] <- intervals[1]
results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the 3.5 million iteration MCMC inference method  $R_{0}$ of 1.5 or 6 for a population size of 1000. min: lower bound of 95\\% credible interval, max: upper bound of 95\\% cedible interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

For $\gamma$, the 95\% credible interval often includes the true value though there are more exceptions than with $\beta$ (Table 5). All credible intervals include the true value of $\gamma$ for population size 50 with an $R_{0}$ of 6, and for all of the outbreak scenarios where population size is 200 (Table 5). For population size 50 and $R_{0}$ of 1.5, the fifth simulation does not include the true $\gamma$ value. When it comes to the outbreaks where population size is 1000, the true $\gamma$ value is not included in the 95\% credible interval. None of the outbreaks with a population size of 1000 and an $R_{0}$ of 6 include the true value in their credible intervals as the intervals are consistently below the true value. A similar situation is seen in the outbreaks where the population size is 1000 and $R_{0}$ is 1.5 where simulations 1 and 5 have credible intervals that are below the true $\gamma$ value of 0.15, though the other three simulations' credible intervals do include 0.15. For population sizes of 50 and 200 for both $R_{0}$s, the mean $\gamma$ values for simulations vary between above and below 0.15. For a population size of 1000, the mean estimated $\gamma$ value is below 0.15 for all 10 outbreaks (Table 5).

% Retired beta and gamma tables
<<MCMC_result_table_beta, cache=FALSE, echo=FALSE, eval=FALSE, results=tex>>=
# Making MCMC table
library("coda")

mcmc_beta_results_table <- array(NA, dim =c(12,10))
burnIn = ((3500000/1000)/100)*23 # 23% burn-in

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

mcmc_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_pop50_seed2 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_22_loglik.csv", sep=""))
mcmc_pop50_seed3 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_40_loglik.csv", sep=""))
mcmc_pop50_seed4 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_43_loglik.csv", sep=""))
mcmc_pop50_seed5 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_95_loglik.csv", sep=""))
mcmc_pop200_seed1 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_pop200_seed2 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_93_loglik.csv", sep=""))
mcmc_pop200_seed3 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_102_loglik.csv", sep=""))
mcmc_pop200_seed4 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_202_loglik.csv", sep =""))
mcmc_pop200_seed5 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_246_loglik.csv", sep =""))
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_246_loglik.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_469_loglik.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_520_loglik.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_784_loglik.csv", sep =""))

mcmc_beta_results_table[2,1] <- 1
mcmc_beta_results_table[3,1] <- 2
mcmc_beta_results_table[4,1] <- 3
mcmc_beta_results_table[5,1] <- 4
mcmc_beta_results_table[6,1] <- 5

mcmc_beta_results_table[8,1] <- 1
mcmc_beta_results_table[9,1] <- 2
mcmc_beta_results_table[10,1] <- 3
mcmc_beta_results_table[11,1] <- 4
mcmc_beta_results_table[12,1] <- 5

# Pop = 50, R0 = 1.5
mcmc_beta_results_table[1,2] <- (1.5 * 0.15) / 50
mcmc_beta_results_table[2,2] <- mean(mcmc_pop50_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[2,3] <- intervals[1]
mcmc_beta_results_table[2,4] <- intervals[2]
mcmc_beta_results_table[3,2] <- mean(mcmc_pop50_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[3,3] <- intervals[1]
mcmc_beta_results_table[3,4] <- intervals[2]
mcmc_beta_results_table[4,2] <- mean(mcmc_pop50_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[4,3] <- intervals[1]
mcmc_beta_results_table[4,4] <- intervals[2]
mcmc_beta_results_table[5,2] <- mean(mcmc_pop50_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[5,3] <- intervals[1]
mcmc_beta_results_table[5,4] <- intervals[2]
mcmc_beta_results_table[6,2] <- mean(mcmc_pop50_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[6,3] <- intervals[1]
mcmc_beta_results_table[6,4] <- intervals[2]
# Pop = 200, R0 = 1.5
mcmc_beta_results_table[1,5] <- (1.5 * 0.15) / 200
mcmc_beta_results_table[2,5] <- mean(mcmc_pop200_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[2,6] <- intervals[1]
mcmc_beta_results_table[2,7] <- intervals[2]
mcmc_beta_results_table[3,5] <- mean(mcmc_pop200_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[3,6] <- intervals[1]
mcmc_beta_results_table[3,7] <- intervals[2]
mcmc_beta_results_table[4,5] <- mean(mcmc_pop200_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[4,6] <- intervals[1]
mcmc_beta_results_table[4,7] <- intervals[2]
mcmc_beta_results_table[5,5] <- mean(mcmc_pop200_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[5,6] <- intervals[1]
mcmc_beta_results_table[5,7] <- intervals[2]
mcmc_beta_results_table[6,5] <- mean(mcmc_pop200_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[6,6] <- intervals[1]
mcmc_beta_results_table[6,7] <- intervals[2]
# Pop = 1000, R0 = 1.5
mcmc_beta_results_table[1,8] <- (1.5 * 0.15) / 1000
mcmc_beta_results_table[2,8] <- mean(mcmc_pop1000_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[2,9] <- intervals[1]
mcmc_beta_results_table[2,10] <- intervals[2]
mcmc_beta_results_table[3,8] <- mean(mcmc_pop1000_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[3,9] <- intervals[1]
mcmc_beta_results_table[3,10] <- intervals[2]
mcmc_beta_results_table[4,8] <- mean(mcmc_pop1000_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[4,9] <- intervals[1]
mcmc_beta_results_table[4,10] <- intervals[2]
mcmc_beta_results_table[5,8] <- mean(mcmc_pop1000_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[5,9] <- intervals[1]
mcmc_beta_results_table[5,10] <- intervals[2]
mcmc_beta_results_table[6,8] <- mean(mcmc_pop1000_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[6,9] <- intervals[1]
mcmc_beta_results_table[6,10] <- intervals[2]

# R0 = 6 Gamma = 0.15
mcmc_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_1_loglik.csv", sep =""))
mcmc_pop50_seed2 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_2_loglik.csv", sep =""))
mcmc_pop50_seed3 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_3_loglik.csv", sep =""))
mcmc_pop50_seed4 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_4_loglik.csv", sep =""))
mcmc_pop50_seed5 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_5_loglik.csv", sep =""))
mcmc_pop200_seed1 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_6_loglik.csv", sep =""))
mcmc_pop200_seed2 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_7_loglik.csv", sep =""))
mcmc_pop200_seed3 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_8_loglik.csv", sep =""))
mcmc_pop200_seed4 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_9_loglik.csv", sep =""))
mcmc_pop200_seed5 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_10_loglik.csv", sep =""))
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_11_loglik.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_12_loglik.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_13_loglik.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_14_loglik.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_15_loglik.csv", sep =""))

# Pop = 50, R0 = 1.5
mcmc_beta_results_table[7,2] <- (6 * 0.15) / 50
mcmc_beta_results_table[8,2] <- mean(mcmc_pop50_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[8,3] <- intervals[1]
mcmc_beta_results_table[8,4] <- intervals[2]
mcmc_beta_results_table[9,2] <- mean(mcmc_pop50_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[9,3] <- intervals[1]
mcmc_beta_results_table[9,4] <- intervals[2]
mcmc_beta_results_table[10,2] <- mean(mcmc_pop50_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[10,3] <- intervals[1]
mcmc_beta_results_table[10,4] <- intervals[2]
mcmc_beta_results_table[11,2] <- mean(mcmc_pop50_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[11,3] <- intervals[1]
mcmc_beta_results_table[11,4] <- intervals[2]
mcmc_beta_results_table[12,2] <- mean(mcmc_pop50_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[12,3] <- intervals[1]
mcmc_beta_results_table[12,4] <- intervals[2]
# Pop = 200, R0 = 1.5
mcmc_beta_results_table[7,5] <- (6 * 0.15) / 200
mcmc_beta_results_table[8,5] <- mean(mcmc_pop200_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[8,6] <- intervals[1]
mcmc_beta_results_table[8,7] <- intervals[2]
mcmc_beta_results_table[9,5] <- mean(mcmc_pop200_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[9,6] <- intervals[1]
mcmc_beta_results_table[9,7] <- intervals[2]
mcmc_beta_results_table[10,5] <- mean(mcmc_pop200_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[10,6] <- intervals[1]
mcmc_beta_results_table[10,7] <- intervals[2]
mcmc_beta_results_table[11,5] <- mean(mcmc_pop200_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[11,6] <- intervals[1]
mcmc_beta_results_table[11,7] <- intervals[2]
mcmc_beta_results_table[12,5] <- mean(mcmc_pop200_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[12,6] <- intervals[1]
mcmc_beta_results_table[12,7] <- intervals[2]
# Pop = 1000, R0 = 1.5
mcmc_beta_results_table[7,8] <- (6 * 0.15) / 1000
mcmc_beta_results_table[8,8] <- mean(mcmc_pop1000_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[8,9] <- intervals[1]
mcmc_beta_results_table[8,10] <- intervals[2]
mcmc_beta_results_table[9,8] <- mean(mcmc_pop1000_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[9,9] <- intervals[1]
mcmc_beta_results_table[9,10] <- intervals[2]
mcmc_beta_results_table[10,8] <- mean(mcmc_pop1000_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[10,9] <- intervals[1]
mcmc_beta_results_table[10,10] <- intervals[2]
mcmc_beta_results_table[11,8] <- mean(mcmc_pop1000_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[11,9] <- intervals[1]
mcmc_beta_results_table[11,10] <- intervals[2]
mcmc_beta_results_table[12,8] <- mean(mcmc_pop1000_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[12,9] <- intervals[1]
mcmc_beta_results_table[12,10] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(mcmc_beta_results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{}  & \\multicolumn{3}{l}{N = 50}  & \\multicolumn{3}{l}{N = 200} & \\multicolumn{3}{l}{N = 1000} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(mcmc_beta_results_table, digits= c(1, 0, 4, 4, 4, 4, 4, 4, 5, 5, 5), caption = "Beta values for the MCMC inference method for each outbreak of a given population size N and R0 of 1.5 or 6. min: minimum value of gamma observed after burn-in during MCMC, max: maximum value of gamma observed after burn-in during MCMC") 
align(tab) <- "lllllllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@
<<MCMC_result_table_gamma, cache=FALSE, echo=FALSE, eval=FALSE, results=tex>>=
# Making Residual Error table
library("coda")

mcmc_results_table <- array(NA, dim =c(12,10))
burnIn = ((3500000/1000)/100)*23 # 23% burn-in
gamma = 0.15

mcmc_results_table[2,1] <- 1
mcmc_results_table[3,1] <- 2
mcmc_results_table[4,1] <- 3
mcmc_results_table[5,1] <- 4
mcmc_results_table[6,1] <- 5

mcmc_results_table[8,1] <- 1
mcmc_results_table[9,1] <- 2
mcmc_results_table[10,1] <- 3
mcmc_results_table[11,1] <- 4
mcmc_results_table[12,1] <- 5

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

mcmc_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_pop50_seed2 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_22_loglik.csv", sep=""))
mcmc_pop50_seed3 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_40_loglik.csv", sep=""))
mcmc_pop50_seed4 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_43_loglik.csv", sep=""))
mcmc_pop50_seed5 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_95_loglik.csv", sep=""))
mcmc_pop200_seed1 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_pop200_seed2 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_93_loglik.csv", sep=""))
mcmc_pop200_seed3 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_102_loglik.csv", sep=""))
mcmc_pop200_seed4 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_202_loglik.csv", sep =""))
mcmc_pop200_seed5 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_246_loglik.csv", sep =""))
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_246_loglik.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_469_loglik.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_520_loglik.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_784_loglik.csv", sep =""))

# Pop = 50, R0 = 1.5
mcmc_results_table[1,2] <- gamma
mcmc_results_table[2,2] <- mean(mcmc_pop50_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[2,3] <- intervals[1]
mcmc_results_table[2,4] <- intervals[2]
mcmc_results_table[3,2] <- mean(mcmc_pop50_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[3,3] <- intervals[1]
mcmc_results_table[3,4] <- intervals[2]
mcmc_results_table[4,2] <- mean(mcmc_pop50_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[4,3] <- intervals[1]
mcmc_results_table[4,4] <- intervals[2]
mcmc_results_table[5,2] <- mean(mcmc_pop50_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[5,3] <- intervals[1]
mcmc_results_table[5,4] <- intervals[2]
mcmc_results_table[6,2] <- mean(mcmc_pop50_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[6,3] <- intervals[1]
mcmc_results_table[6,4] <- intervals[2]
# Pop = 200, R0 = 1.5
mcmc_results_table[1,5] <- gamma
mcmc_results_table[2,5] <- mean(mcmc_pop200_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[2,6] <- intervals[1]
mcmc_results_table[2,7] <- intervals[2]
mcmc_results_table[3,5] <- mean(mcmc_pop200_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[3,6] <- intervals[1]
mcmc_results_table[3,7] <- intervals[2]
mcmc_results_table[4,5] <- mean(mcmc_pop200_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[4,6] <- intervals[1]
mcmc_results_table[4,7] <- intervals[2]
mcmc_results_table[5,5] <- mean(mcmc_pop200_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[5,6] <- intervals[1]
mcmc_results_table[5,7] <- intervals[2]
mcmc_results_table[6,5] <- mean(mcmc_pop200_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[6,6] <- intervals[1]
mcmc_results_table[6,7] <- intervals[2]
# Pop = 1000, R0 = 1.5
mcmc_results_table[1,8] <- gamma
mcmc_results_table[2,8] <- mean(mcmc_pop1000_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[2,9] <- intervals[1]
mcmc_results_table[2,10] <- intervals[2]
mcmc_results_table[3,8] <- mean(mcmc_pop1000_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[3,9] <- intervals[1]
mcmc_results_table[3,10] <- intervals[2]
mcmc_results_table[4,8] <- mean(mcmc_pop1000_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[4,9] <- intervals[1]
mcmc_results_table[4,10] <- intervals[2]
mcmc_results_table[5,8] <- mean(mcmc_pop1000_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[5,9] <- intervals[1]
mcmc_results_table[5,10] <- intervals[2]
mcmc_results_table[6,8] <- mean(mcmc_pop1000_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[6,9] <- intervals[1]
mcmc_results_table[6,10] <- intervals[2]

# R0 = 6 Gamma = 0.15
mcmc_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_1_loglik.csv", sep =""))
mcmc_pop50_seed2 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_2_loglik.csv", sep =""))
mcmc_pop50_seed3 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_3_loglik.csv", sep =""))
mcmc_pop50_seed4 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_4_loglik.csv", sep =""))
mcmc_pop50_seed5 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_5_loglik.csv", sep =""))
mcmc_pop200_seed1 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_6_loglik.csv", sep =""))
mcmc_pop200_seed2 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_7_loglik.csv", sep =""))
mcmc_pop200_seed3 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_8_loglik.csv", sep =""))
mcmc_pop200_seed4 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_9_loglik.csv", sep =""))
mcmc_pop200_seed5 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_10_loglik.csv", sep =""))
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_11_loglik.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_12_loglik.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_13_loglik.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_14_loglik.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_15_loglik.csv", sep =""))

# Pop = 50, R0 = 6
mcmc_results_table[7,2] <- gamma
mcmc_results_table[8,2] <- mean(mcmc_pop50_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[8,3] <- intervals[1]
mcmc_results_table[8,4] <- intervals[2]
mcmc_results_table[9,2] <- mean(mcmc_pop50_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[9,3] <- intervals[1]
mcmc_results_table[9,4] <- intervals[2]
mcmc_results_table[10,2] <- mean(mcmc_pop50_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[10,3] <- intervals[1]
mcmc_results_table[10,4] <- intervals[2]
mcmc_results_table[11,2] <- mean(mcmc_pop50_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[11,3] <- intervals[1]
mcmc_results_table[11,4] <- intervals[2]
mcmc_results_table[12,2] <- mean(mcmc_pop50_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop50_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[12,3] <- intervals[1]
mcmc_results_table[12,4] <- intervals[2]
# Pop = 200, R0 = 6
mcmc_results_table[7,5] <- gamma
mcmc_results_table[8,5] <- mean(mcmc_pop200_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[8,6] <- intervals[1]
mcmc_results_table[8,7] <- intervals[2]
mcmc_results_table[9,5] <- mean(mcmc_pop200_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[9,6] <- intervals[1]
mcmc_results_table[9,7] <- intervals[2]
mcmc_results_table[10,5] <- mean(mcmc_pop200_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[10,6] <- intervals[1]
mcmc_results_table[10,7] <- intervals[2]
mcmc_results_table[11,5] <- mean(mcmc_pop200_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[11,6] <- intervals[1]
mcmc_results_table[11,7] <- intervals[2]
mcmc_results_table[12,5] <- mean(mcmc_pop200_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop200_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[12,6] <- intervals[1]
mcmc_results_table[12,7] <- intervals[2]
# Pop = 1000, R0 = 6
mcmc_results_table[7,8] <- gamma
mcmc_results_table[8,8] <- mean(mcmc_pop1000_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[8,9] <- intervals[1]
mcmc_results_table[8,10] <- intervals[2]
mcmc_results_table[9,8] <- mean(mcmc_pop1000_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[9,9] <- intervals[1]
mcmc_results_table[9,10] <- intervals[2]
mcmc_results_table[10,8] <- mean(mcmc_pop1000_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[10,9] <- intervals[1]
mcmc_results_table[10,10] <- intervals[2]
mcmc_results_table[11,8] <- mean(mcmc_pop1000_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[11,9] <- intervals[1]
mcmc_results_table[11,10] <- intervals[2]
mcmc_results_table[12,8] <- mean(mcmc_pop1000_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_results_table[12,9] <- intervals[1]
mcmc_results_table[12,10] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(mcmc_results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{}  & \\multicolumn{3}{l}{N = 50}  & \\multicolumn{3}{l}{N = 200} & \\multicolumn{3}{l}{N = 1000} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(mcmc_results_table, digits = c(1, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2), caption = "$\\gamma$ values for the MCMC inference method for each outbreak of a given population size N and $R_{0}$ of 1.5 or 6. min: minimum value of $\\gamma$ observed after burn-in during MCMC, max: maximum value of $\\gamma$ observed after burn-in during MCMC") 
align(tab) <- "lllllllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

The traces for $\beta$ and $\gamma$ showing the trace for the first simulation of each population size and $R_{0}$ combination suggest that the MCMC has not always fully converged during the 3.5 million iterations, epecially for the larger population sizes (Fig. 7, Fig. 8). The $\beta$ trace for population size 50 and $R_{0}$ of 6 looks the closest to having reached convergence (Fig. 7D), while the traces for the largest population size (Fig 7C,F) look to be the furthest from being converged, which is in concordance with the $\beta$ 95\% credible intervals for population size 1000 often excluding the true $\beta$ value in Table 4. 

\begin{figure}[h]
\begin{center}
<<dataplot4, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, height=13, width=19, fig.cap="Data plot", fig=TRUE>>=
# Beta posterior plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

letter_size = 3
iteration_place = 3400
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2,3), mar=c(5,6.5,1.5,1))

burnIn = ((3500000/1000)/100)*23 # 23% burn-in
beta_yaxis50 = c(0, 0.025)
beta_yaxis200 = c(0, 0.007)
beta_yaxis1000 = c(0, 0.001)
# Seed 1, Pop size 50
plot(mcmc_R1.5_pop50_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis50, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis50), "A", cex = letter_size)
mtext("Beta value", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 1, Pop size 200
plot(mcmc_R1.5_pop200_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis200, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis200), "B", cex = letter_size)
# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis1000, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis1000), "C", cex = letter_size)
# Seed 1, Pop size 50
plot(mcmc_R6_pop50_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis50, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis50), "D", cex = letter_size)
mtext("Beta value", 2, line = 3, cex = yaxis_size, outer = FALSE)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 200
plot(mcmc_R6_pop200_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis200, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis200), "E", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis1000, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis1000), "F", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
@
\caption{Traces of the $\beta$ values throughout the MCMC. Plots A-C are for outbreaks with an $R_{0}$ of 1.5, while plots D-F are for outbreaks with an $R_{0}$ of 6. Plots A and D have a population size of 50, plots B and E have a population size of 200, and plots C and F have a population size of 1000.}
\end{center}
\end{figure}

A similar situation for the $\gamma$ traces can be seen as for $\beta$ traces. Here again the trace for population size 50 and $R_{0}$ of 6 is looking most converged (Fig. 8D). None of the $\gamma$ traces for population size 200 (Fig. 8B, E) or population size 1000 (Fig. 8C, F) look fully converged. Additionally, in Figure 8 seems that the variance in $\gamma$ values decreases with increasing population size.

\begin{figure}[h]
\begin{center}
<<dataplot6, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, fig.pos="H", height=13, width=19, fig.cap="Data plot", fig=TRUE>>=
# Beta and gamma posterior plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

letter_size = 3
iteration_place = 3400
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2,3), mar=c(5,6.5,1.5,1))

burnIn = ((3500000/1000)/100)*23 # 23% burn-in
gamma_yaxis50 = c(0, 0.35)
gamma_yaxis200 = c(0, 0.25)
gamma_yaxis1000 = c(0, 0.15)

# Seed 1, Pop size 50
plot(mcmc_R1.5_pop50_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis50, cex.axis=number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis50), "A", cex = letter_size)
mtext("Gamma value", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 1, Pop size 200
plot(mcmc_R1.5_pop200_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis200, cex.axis=number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis200), "B", cex = letter_size)
# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis1000, cex.axis=number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis1000), "C", cex = letter_size)
# Seed 1, Pop size 50
plot(mcmc_R6_pop50_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis50, cex.axis=number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis50), "D", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
mtext("Gamma value", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 1, Pop size 200
plot(mcmc_R6_pop200_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis200, cex.axis=number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis200), "E", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis1000, cex.axis=number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis1000), "F", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
@
\caption{Traces of the $\gamma$ values throughout the MCMC. Plots A-C are for outbreaks with an $R_{0}$ of 1.5, while plots D-F are for outbreaks with an $R_{0}$ of 6. Plots A and D have a population size of 50, plots B and E have a population size of 200, and plots C and F have a population size of 1000. }
\end{center}
\end{figure}

<<dataplot4, cache=FALSE, echo=FALSE, eval=FALSE, dpi=100, fig.pos="H", fig.height=4, fig.cap="Data plot", fig=TRUE>>=
# Log likelihood plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

par(mfrow = c(2,3), mar=c(3.5,4,1.2,0.5))

burnIn = ((3500000/1000)/100)*23 # 23% burn-in
yaxis = c(-2000, -100)
# Seed 1, Pop size 50
plot(mcmc_R1.5_pop50_seed1$loglik, type = "l", main = "", xlab = "Iteration x1000", ylab = "Log(likelihood)", ylim = yaxis)
  abline(v = burnIn, untf = FALSE)
  # mtext("Iteration x1000",side=1,line=2)
# Seed 1, Pop size 200
plot(mcmc_R1.5_pop200_seed1$loglik, type = "l", main = "", xlab = "Iteration x1000", ylab = "Log(likelihood)", ylim = yaxis)
  abline(v = burnIn, untf = FALSE)
  # mtext("Iteration x1000",side=1,line=2)
# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$loglik, type = "l", main = "", xlab = "Iteration x1000", ylab = "Log(likelihood)", ylim = yaxis)
  abline(v = burnIn, untf = FALSE)
  # mtext("Iteration x1000",side=1,line=2)
# Seed 1, Pop size 50
plot(mcmc_R6_pop50_seed1$loglik, type = "l", main = "", xlab = "Iteration x1000", ylab = "Log(likelihood)", ylim = yaxis)
  abline(v = burnIn, untf = FALSE)
  # mtext("Iteration x1000",side=1,line=2)
# Seed 1, Pop size 200
plot(mcmc_R6_pop200_seed1$loglik, type = "l", main = "", xlab = "Iteration x1000", ylab = "Log(likelihood)", ylim = yaxis)
  abline(v = burnIn, untf = FALSE)
  # mtext("Iteration x1000",side=1,line=2)
# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$loglik, type = "l", main = "", xlab = "Iteration x1000", ylab = "Log(likelihood)", ylim = yaxis)
  abline(v = burnIn, untf = FALSE)
  # smtext("Iteration x1000",side=1,line=2)
@

The range of log-likelihoods is quite varying for different outbreaks within a given $R_{0}$ and population size (Table 7). This is because the likelihood function was set to return a value of -1000 if the suggested parameters fit the data point with a likelihood of 0, due to the computational difficulties associated with attempting to calculate $log(0)$.

<<MCMC_result_table_loglik, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making Log likelihood table
library("coda")
mcmc_results_table <- array(NA, dim =c(10,10))
burnIn = ((3500000/1000)/100)*23 # 23% burn-in

mcmc_results_table[1,1] <- 1
mcmc_results_table[2,1] <- 2
mcmc_results_table[3,1] <- 3
mcmc_results_table[4,1] <- 4
mcmc_results_table[5,1] <- 5

mcmc_results_table[6,1] <- 1
mcmc_results_table[7,1] <- 2
mcmc_results_table[8,1] <- 3
mcmc_results_table[9,1] <- 4
mcmc_results_table[10,1] <- 5

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

mcmc_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_pop50_seed2 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_22_loglik.csv", sep=""))
mcmc_pop50_seed3 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_40_loglik.csv", sep=""))
mcmc_pop50_seed4 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_43_loglik.csv", sep=""))
mcmc_pop50_seed5 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_95_loglik.csv", sep=""))
mcmc_pop200_seed1 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_pop200_seed2 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_93_loglik.csv", sep=""))
mcmc_pop200_seed3 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_102_loglik.csv", sep=""))
mcmc_pop200_seed4 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_202_loglik.csv", sep =""))
mcmc_pop200_seed5 <- read.csv(paste(dir, "mcmc_pop200_R1.5_g0.15_246_loglik.csv", sep =""))
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_246_loglik.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_469_loglik.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_520_loglik.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_784_loglik.csv", sep =""))

# Pop = 50, R0 = 1.5
mcmc_results_table[1,2] <- mean(mcmc_pop50_seed1$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed1$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[1,3] <- intervals[1]
mcmc_results_table[1,4] <- intervals[2]
mcmc_results_table[2,2] <- mean(mcmc_pop50_seed2$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed2$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[2,3] <- intervals[1]
mcmc_results_table[2,4] <- intervals[2]
mcmc_results_table[3,2] <- mean(mcmc_pop50_seed3$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed3$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[3,3] <- intervals[1]
mcmc_results_table[3,4] <- intervals[2]
mcmc_results_table[4,2] <- mean(mcmc_pop50_seed4$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed4$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[4,3] <- intervals[1]
mcmc_results_table[4,4] <- intervals[2]
mcmc_results_table[5,2] <- mean(mcmc_pop50_seed5$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed5$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[5,3] <- intervals[1]
mcmc_results_table[5,4] <- intervals[2]
# Pop = 200, R0 = 1.5
mcmc_results_table[1,5] <- mean(mcmc_pop200_seed1$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed1$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[1,6] <- intervals[1]
mcmc_results_table[1,7] <- intervals[2]
mcmc_results_table[2,5] <- mean(mcmc_pop200_seed2$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed2$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[2,6] <- intervals[1]
mcmc_results_table[2,7] <- intervals[2]
mcmc_results_table[3,5] <- mean(mcmc_pop200_seed3$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed3$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[3,6] <- intervals[1]
mcmc_results_table[3,7] <- intervals[2]
mcmc_results_table[4,5] <- mean(mcmc_pop200_seed4$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed4$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[4,6] <- intervals[1]
mcmc_results_table[4,7] <- intervals[2]
mcmc_results_table[5,5] <- mean(mcmc_pop200_seed5$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed5$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[5,6] <- intervals[1]
mcmc_results_table[5,7] <- intervals[2]
# Pop = 1000, R0 = 1.5
mcmc_results_table[1,8] <- mean(mcmc_pop1000_seed1$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed1$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[1,9] <- intervals[1]
mcmc_results_table[1,10] <- intervals[2]
mcmc_results_table[2,8] <- mean(mcmc_pop1000_seed2$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed2$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[2,9] <- intervals[1]
mcmc_results_table[2,10] <- intervals[2]
mcmc_results_table[3,8] <- mean(mcmc_pop1000_seed3$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed3$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[3,9] <- intervals[1]
mcmc_results_table[3,10] <- intervals[2]
mcmc_results_table[4,8] <- mean(mcmc_pop1000_seed4$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed4$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[4,9] <- intervals[1]
mcmc_results_table[4,10] <- intervals[2]
mcmc_results_table[5,8] <- mean(mcmc_pop1000_seed5$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed5$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[5,9] <- intervals[1]
mcmc_results_table[5,10] <- intervals[2]

# R0 = 6 Gamma = 0.15
mcmc_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_1_loglik.csv", sep =""))
mcmc_pop50_seed2 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_2_loglik.csv", sep =""))
mcmc_pop50_seed3 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_3_loglik.csv", sep =""))
mcmc_pop50_seed4 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_4_loglik.csv", sep =""))
mcmc_pop50_seed5 <- read.csv(paste(dir, "mcmc_pop50_R6_g0.15_5_loglik.csv", sep =""))
mcmc_pop200_seed1 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_6_loglik.csv", sep =""))
mcmc_pop200_seed2 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_7_loglik.csv", sep =""))
mcmc_pop200_seed3 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_8_loglik.csv", sep =""))
mcmc_pop200_seed4 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_9_loglik.csv", sep =""))
mcmc_pop200_seed5 <- read.csv(paste(dir, "mcmc_pop200_R6_g0.15_10_loglik.csv", sep =""))
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_11_loglik.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_12_loglik.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_13_loglik.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_14_loglik.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_15_loglik.csv", sep =""))

# Pop = 50, R0 = 6
mcmc_results_table[6,2] <- mean(mcmc_pop50_seed1$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed1$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[6,3] <- intervals[1]
mcmc_results_table[6,4] <- intervals[2]
mcmc_results_table[7,2] <- mean(mcmc_pop50_seed2$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed2$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[7,3] <- intervals[1]
mcmc_results_table[7,4] <- intervals[2]
mcmc_results_table[8,2] <- mean(mcmc_pop50_seed3$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed3$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[8,3] <- intervals[1]
mcmc_results_table[8,4] <- intervals[2]
mcmc_results_table[9,2] <- mean(mcmc_pop50_seed4$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed4$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[9,3] <- intervals[1]
mcmc_results_table[9,4] <- intervals[2]
mcmc_results_table[10,2] <- mean(mcmc_pop50_seed5$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop50_seed5$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[10,3] <- intervals[1]
mcmc_results_table[10,4] <- intervals[2]
# Pop = 200, R0 = 6
mcmc_results_table[6,5] <- mean(mcmc_pop200_seed1$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed1$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[6,6] <- intervals[1]
mcmc_results_table[6,7] <- intervals[2]
mcmc_results_table[7,5] <- mean(mcmc_pop200_seed2$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed2$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[7,6] <- intervals[1]
mcmc_results_table[7,7] <- intervals[2]
mcmc_results_table[8,5] <- mean(mcmc_pop200_seed3$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed3$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[8,6] <- intervals[1]
mcmc_results_table[8,7] <- intervals[2]
mcmc_results_table[9,5] <- mean(mcmc_pop200_seed4$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed4$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[9,6] <- intervals[1]
mcmc_results_table[9,7] <- intervals[2]
mcmc_results_table[10,5] <- mean(mcmc_pop200_seed5$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop200_seed5$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[10,6] <- intervals[1]
mcmc_results_table[10,7] <- intervals[2]
# Pop = 1000, R0 = 6
mcmc_results_table[6,8] <- mean(mcmc_pop1000_seed1$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed1$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[6,9] <- intervals[1]
mcmc_results_table[6,10] <- intervals[2]
mcmc_results_table[7,8] <- mean(mcmc_pop1000_seed2$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed2$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[7,9] <- intervals[1]
mcmc_results_table[7,10] <- intervals[2]
mcmc_results_table[8,8] <- mean(mcmc_pop1000_seed3$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed3$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[8,9] <- intervals[1]
mcmc_results_table[8,10] <- intervals[2]
mcmc_results_table[9,8] <- mean(mcmc_pop1000_seed4$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed4$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[9,9] <- intervals[1]
mcmc_results_table[9,10] <- intervals[2]
mcmc_results_table[10,8] <- mean(mcmc_pop1000_seed5$loglik[-(1:burnIn)])
intervals <- HPDinterval(mcmc(mcmc_pop1000_seed5$loglik[-(1:burnIn)]), 0.95)
mcmc_results_table[10,9] <- intervals[1]
mcmc_results_table[10,10] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(mcmc_results_table) <- c("1.5", ".","..","...","....","6","-","--","---","----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{}  & \\multicolumn{3}{l}{N = 50}  & \\multicolumn{3}{l}{N = 200} & \\multicolumn{3}{l}{N = 1000} \\\\\n", "R0 & sim & mean & min & max & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(mcmc_results_table, digits = 0, caption = "Log(likelihood) values for the MCMC inference method for each outbreak of a given population size N and $R_{0}$ of 1.5 or 6. min: minimum log(likelihood) after burn-in during MCMC, max: maximum log(likelihood) observed after burn-in during MCMC") 
align(tab) <- "lllllllllll"
print(tab, hline.after=c(-1, 0, 10), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

The range of suggested infectious curves after the burn-in period in general overlaps with the true generated infectious curve (Figure 7). An exception for this is one of the unconverged MCMCs in Figure 7F, where the MCMC's augmented infectious curves are not yet overlapping with the true infectious curve. The range of infectious curves produced is widest for the smallest population size and $R_{0}$ (Figure 7A). For each of the $R_{0}$s, the range of infectious curves produced narrows with an increasing population size (Figure 7A-C and Figure 7D-F).

\begin{figure}[h]
\begin{center}
<<dataplot5, cache=FALSE, echo=FALSE, eval=FALSE, dpi=100, height=13, width=17, fig.cap="Data plot", fig=TRUE>>=
# Infectious curve plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_infectious.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R1.5_g0.15_81_infectious.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_infectious.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"mcmc_pop50_R6_g0.15_2_infectious.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R6_g0.15_6_infectious.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_infectious.csv", sep=""))

true_R1.5_pop50_seed1 <- read.csv("data_pop50_R1.5_g0.15_14.csv")
true_R1.5_pop200_seed1 <- read.csv("data_pop200_R1.5_g0.15_81.csv")
true_R1.5_pop1000_seed1 <- read.csv("data_pop1000_R1.5_g0.15_177.csv")
true_R6_pop50_seed1 <- read.csv("data_pop50_R6_g0.15_2.csv")
true_R6_pop200_seed1 <- read.csv("data_pop200_R6_g0.15_6.csv")
true_R6_pop1000_seed1 <- read.csv("data_pop1000_R6_g0.15_11.csv")

par(mfrow = c(2,3))

burnIn = ((3500000/1000)/100)*23 # 23% burn-in

letter_size = 3
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2, 3), mar=c(5,6.5,0.4,0.2))

# Pop size = 50
N = 50
timestep_diff <- nrow(mcmc_R1.5_pop50_seed1) - nrow(true_R1.5_pop50_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R1.5_pop50_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R1.5_pop50_seed1 <- rbind(zero_array, true_R1.5_pop50_seed1)
true_R1.5_pop50_seed1$time <- mcmc_R1.5_pop50_seed1[,1]

plot(true_R1.5_pop50_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R1.5_pop50_seed1)){
  lines(mcmc_R1.5_pop50_seed1[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R1.5_pop50_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(150, 0.95*N, "A", cex = letter_size)
mtext("Number infected", 2, line = 4, cex = yaxis_size, outer = FALSE)
# Pop size 200
N = 200
timestep_diff <- nrow(mcmc_R1.5_pop200_seed1) - nrow(true_R1.5_pop200_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R1.5_pop200_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R1.5_pop200_seed1 <- rbind(zero_array, true_R1.5_pop200_seed1)
true_R1.5_pop200_seed1$time <- mcmc_R1.5_pop200_seed1[,1]

plot(true_R1.5_pop200_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R1.5_pop200_seed1)){
  lines(mcmc_R1.5_pop200_seed1[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R1.5_pop200_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(150, 0.95*N, "B", cex = letter_size)
# Pop size 1000
N = 1000
timestep_diff <- nrow(mcmc_R1.5_pop1000_seed1) - nrow(true_R1.5_pop1000_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R1.5_pop1000_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R1.5_pop1000_seed1 <- rbind(zero_array, true_R1.5_pop1000_seed1)
true_R1.5_pop1000_seed1$time <- mcmc_R1.5_pop1000_seed1[,1]

plot(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R1.5_pop1000_seed1)){
  lines(mcmc_R1.5_pop1000_seed1[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(150, 0.95*N, "C", cex = letter_size)
# Pop size 50
N = 50
timestep_diff <- nrow(mcmc_R6_pop50_seed1) - nrow(true_R6_pop50_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R6_pop50_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R6_pop50_seed1 <- rbind(zero_array, true_R6_pop50_seed1)
true_R6_pop50_seed1$time <- mcmc_R6_pop50_seed1[,1]

plot(true_R6_pop50_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R6_pop50_seed1)){
  lines(mcmc_R6_pop50_seed1[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R6_pop50_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(150, 0.95*N, "D", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
mtext("Number infected", 2, line = 4, cex = yaxis_size, outer = FALSE)
# Pop size 200
N = 200
timestep_diff <- nrow(mcmc_R6_pop200_seed1) - nrow(true_R6_pop200_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R6_pop200_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R6_pop200_seed1 <- rbind(zero_array, true_R6_pop200_seed1)
true_R6_pop200_seed1$time <- mcmc_R6_pop200_seed1[,1]

plot(true_R6_pop200_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R6_pop200_seed1)){
  lines(mcmc_R6_pop200_seed1[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R6_pop200_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(150, 0.95*N, "E", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
# Pop size 1000
N = 1000
timestep_diff <- nrow(mcmc_R6_pop1000_seed1) - nrow(true_R6_pop1000_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R6_pop1000_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R6_pop1000_seed1 <- rbind(zero_array, true_R6_pop1000_seed1)
true_R6_pop1000_seed1$time <- mcmc_R6_pop1000_seed1[,1]

plot(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R6_pop1000_seed1)){
  lines(mcmc_R6_pop1000_seed1[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(150, 0.95*N, "F", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
@
\caption{Comparing the infectious curves of the MCMC to the true curve. The red line depicts the number of individuals in a population infected in the true dataset. The grey dotted lines refer to the post-burn-in period infectious curves used by the MCMC. Figures A-C and D-F represent outbreaks with an $R_{0}$ of 1.5 and 6, respectively. Figures A and D represent a population size of 50, Figures B and E represent a population size of 200, and figures C and F represent a population size of 1000.}
\end{center}
\end{figure}

For the 17.5 million iteration run for the largest population size, the MCMC did converge.

<<MCMC_result_table_long, cache=FALSE, echo=FALSE, eval=TRUE, results=tex>>=
# Making MCMC table

mcmc_beta_results_table <- array(NA, dim =c(12,7))
burnIn = ((17500000/1000)/100)*23 # 23% burn-in

# setwd("/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data")
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"

mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_177_loglik_long.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_246_loglik_long.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_469_loglik_long.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R1.5_g0.15_520_loglik_long.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_784_loglik_long.csv", sep =""))

mcmc_beta_results_table[2,1] <- 1
mcmc_beta_results_table[3,1] <- 2
mcmc_beta_results_table[4,1] <- 3
mcmc_beta_results_table[5,1] <- 4
mcmc_beta_results_table[6,1] <- 5

mcmc_beta_results_table[8,1] <- 1
mcmc_beta_results_table[9,1] <- 2
mcmc_beta_results_table[10,1] <- 3
mcmc_beta_results_table[11,1] <- 4
mcmc_beta_results_table[12,1] <- 5

# Pop = 1000, R0 = 1.5
mcmc_beta_results_table[1,2] <- (1.5 * 0.15) / 1000
mcmc_beta_results_table[2,2] <- mean(mcmc_pop1000_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[2,3] <- intervals[1]
mcmc_beta_results_table[2,4] <- intervals[2]
mcmc_beta_results_table[3,2] <- mean(mcmc_pop1000_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[3,3] <- intervals[1]
mcmc_beta_results_table[3,4] <- intervals[2]
mcmc_beta_results_table[4,2] <- mean(mcmc_pop1000_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[4,3] <- intervals[1]
mcmc_beta_results_table[4,4] <- intervals[2]
mcmc_beta_results_table[5,2] <- mean(mcmc_pop1000_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[5,3] <- intervals[1]
mcmc_beta_results_table[5,4] <- intervals[2]
mcmc_beta_results_table[6,2] <- mean(mcmc_pop1000_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[6,3] <- intervals[1]
mcmc_beta_results_table[6,4] <- intervals[2]

# Pop = 1000, R0 = 1.5
mcmc_beta_results_table[1,5] <- 0.15
mcmc_beta_results_table[2,5] <- mean(mcmc_pop1000_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[2,6] <- intervals[1]
mcmc_beta_results_table[2,7] <- intervals[2]
mcmc_beta_results_table[3,5] <- mean(mcmc_pop1000_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[3,6] <- intervals[1]
mcmc_beta_results_table[3,7] <- intervals[2]
mcmc_beta_results_table[4,5] <- mean(mcmc_pop1000_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[4,6] <- intervals[1]
mcmc_beta_results_table[4,7] <- intervals[2]
mcmc_beta_results_table[5,5] <- mean(mcmc_pop1000_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[5,6] <- intervals[1]
mcmc_beta_results_table[5,7] <- intervals[2]
mcmc_beta_results_table[6,5] <- mean(mcmc_pop1000_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[6,6] <- intervals[1]
mcmc_beta_results_table[6,7] <- intervals[2]

# R0 = 6 Gamma = 0.15
mcmc_pop1000_seed1 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_11_loglik_long.csv", sep =""))
mcmc_pop1000_seed2 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_12_loglik_long.csv", sep =""))
mcmc_pop1000_seed3 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_13_loglik_long.csv", sep =""))
mcmc_pop1000_seed4 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_14_loglik_long.csv", sep =""))
mcmc_pop1000_seed5 <- read.csv(paste(dir, "mcmc_pop1000_R6_g0.15_15_loglik_long.csv", sep =""))

# Pop = 1000, R0 = 6
mcmc_beta_results_table[7,2] <- (6 * 0.15) / 1000
mcmc_beta_results_table[8,2] <- mean(mcmc_pop1000_seed1$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[8,3] <- intervals[1]
mcmc_beta_results_table[8,4] <- intervals[2]
mcmc_beta_results_table[9,2] <- mean(mcmc_pop1000_seed2$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[9,3] <- intervals[1]
mcmc_beta_results_table[9,4] <- intervals[2]
mcmc_beta_results_table[10,2] <- mean(mcmc_pop1000_seed3$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[10,3] <- intervals[1]
mcmc_beta_results_table[10,4] <- intervals[2]
mcmc_beta_results_table[11,2] <- mean(mcmc_pop1000_seed4$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[11,3] <- intervals[1]
mcmc_beta_results_table[11,4] <- intervals[2]
mcmc_beta_results_table[12,2] <- mean(mcmc_pop1000_seed5$beta[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$beta[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[12,3] <- intervals[1]
mcmc_beta_results_table[12,4] <- intervals[2]

# Pop = 1000, R0 = 6
mcmc_beta_results_table[7,5] <- 0.15
mcmc_beta_results_table[8,5] <- mean(mcmc_pop1000_seed1$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed1$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[8,6] <- intervals[1]
mcmc_beta_results_table[8,7] <- intervals[2]
mcmc_beta_results_table[9,5] <- mean(mcmc_pop1000_seed2$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed2$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[9,6] <- intervals[1]
mcmc_beta_results_table[9,7] <- intervals[2]
mcmc_beta_results_table[10,5] <- mean(mcmc_pop1000_seed3$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed3$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[10,6] <- intervals[1]
mcmc_beta_results_table[10,7] <- intervals[2]
mcmc_beta_results_table[11,5] <- mean(mcmc_pop1000_seed4$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed4$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[11,6] <- intervals[1]
mcmc_beta_results_table[11,7] <- intervals[2]
mcmc_beta_results_table[12,5] <- mean(mcmc_pop1000_seed5$gamma[-(1:burnIn)])
intervals <- quantile(mcmc_pop1000_seed5$gamma[-(1:burnIn)], c(0.025, 0.975))
mcmc_beta_results_table[12,6] <- intervals[1]
mcmc_beta_results_table[12,7] <- intervals[2]

##############################
# Making Residual Error table
library('xtable')
# options(xtable.floating = FALSE)
# options(xtable.timestamp = "")

rownames(mcmc_beta_results_table) <- c("1.5", ".","..","...","....",".....","6","-","--","---","----","-----")

addtorow <- list()
addtorow$pos <- list(0, 0)
addtorow$command <- c("& \\multicolumn{1}{l}{} & \\multicolumn{3}{l}{$\\beta$}  & \\multicolumn{3}{l}{$\\gamma$} \\\\\n", "$R_{0}$ & sim & mean & min & max & mean & min & max \\\\\n")

tab <- xtable(mcmc_beta_results_table, digits= c(1, 0, -1, -1, -1, 2, 2, 2), caption = "$\\beta$ and $\\gamma$ values for the 17.5 million iteration MCMC inference method  $R_{0}$ of 1.5 or 6 for a population size of 1000. min: lower bound of 95\\% credible interval, max: upper bound of 95\\% credible interval") 
align(tab) <- "llllllll"
print(tab, hline.after=c(-1, 0, 12), comment = FALSE, math.style.exponents = FALSE, caption.placement = "top", add.to.row = addtorow, include.colnames = FALSE, type="latex")
@

\begin{figure}[h]
\begin{center}
<<longmcmcplot, cache=FALSE, echo=FALSE, eval=FALSE, dpi=100, height=13, width=17, fig.cap="Data plot", fig=TRUE>>=
# Infectious curve plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_loglik_long.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_loglik_long.csv", sep=""))
mcmc_R1.5_pop1000_inf <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_infectious_long.csv", sep=""))
mcmc_R6_pop1000_inf <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_infectious_long.csv", sep=""))

true_R1.5_pop1000_seed1 <- read.csv("data_pop1000_R1.5_g0.15_177.csv")
true_R6_pop1000_seed1 <- read.csv("data_pop1000_R6_g0.15_11.csv")

burnIn = ((17500000/1000)/100)*23 # 23% burn-in
burnIn_1.5 = 8000 # ((17500000/1000)/100)*23

letter_size = 3
axis_size = 2.5
yaxis_size = 2
number_size = 2.5
beta_yaxis1000_1.5 = c(0, 0.0005)
beta_yaxis1000_6 = c(0, 0.0015)
gamma_yaxis1000_1.5 = c(0, 0.3)
gamma_yaxis1000_6 = c(0, 0.2)
iteration_place = 17500*0.9

par(mfrow = c(2, 3), mar=c(5.5,6.5,1.5,0.2))

# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis1000_1.5, cex.axis = number_size)
  abline(v = burnIn_1.5, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis1000_1.5), "A", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
mtext("Beta value", 2, line = 3, cex = yaxis_size, outer = FALSE)

# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis1000_1.5, cex.axis = number_size)
  abline(v = burnIn_1.5, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis1000_1.5), "B", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
mtext("Gamma value", 2, line = 3, cex = yaxis_size, outer = FALSE)

# Pop size 1000
N = 1000
timestep_diff <- nrow(mcmc_R1.5_pop1000_inf) - nrow(true_R1.5_pop1000_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R1.5_pop1000_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R1.5_pop1000_seed1 <- rbind(zero_array, true_R1.5_pop1000_seed1)
true_R1.5_pop1000_seed1$time <- mcmc_R1.5_pop1000_inf[,1]

plot(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn_1.5:ncol(mcmc_R1.5_pop1000_inf)){
  lines(mcmc_R1.5_pop1000_inf[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(160, 0.95*N, "C", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
mtext("Number infected", 2, line = 3, cex = yaxis_size, outer = FALSE)

# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis1000_6, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis1000_6), "D", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
mtext("Beta value", 2, line = 3, cex = yaxis_size, outer = FALSE)

# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis1000_6, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis1000_6), "E", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
mtext("Gamma value", 2, line = 3, cex = yaxis_size, outer = FALSE)

# Pop size 1000
N = 1000
timestep_diff <- nrow(mcmc_R6_pop1000_inf) - nrow(true_R6_pop1000_seed1)
zero_array <- array(0, dim = c(timestep_diff, ncol(true_R6_pop1000_seed1)))
colnames(zero_array) <- c("time","S", "I", "R", "new_I", "new_R")
true_R6_pop1000_seed1 <- rbind(zero_array, true_R6_pop1000_seed1)
true_R6_pop1000_seed1$time <- mcmc_R6_pop1000_inf[,1]

plot(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", main = "", cex.axis = number_size)
for (i in burnIn:ncol(mcmc_R6_pop1000_inf)){
  lines(mcmc_R6_pop1000_inf[,i], type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
lines(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
text(160, 0.95*N, "F", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
mtext("Number infected", 2, line = 3, cex = yaxis_size, outer = FALSE)
@
\caption{Comparing the infectious curves of the MCMC to the true curve. The red line depicts the number of individuals in a population infected in the true dataset. The grey dotted lines refer to the post-burn-in period infectious curves used by the MCMC. Figures A-C and D-F represent outbreaks with an $R_{0}$ of 1.5 and 6, respectively. Figures A and D represent a population size of 50, Figures B and E represent a population size of 200, and figures C and F represent a population size of 1000.}
\end{center}
\end{figure}

\begin{figure}
\begin{center}
<<mcmcdensityplot, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, height=10, width=14, fig.cap="Data plot", fig=TRUE>>=
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop200 <- read.csv(paste(dir,"mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))

burnIn = 3500 * 0.23
# Plot beta vs. gamma
par(mfrow = c(1,1))
library(RColorBrewer)
library(MASS)

k <- 11
my.cols <- rev(brewer.pal(k, "RdYlBu"))
z <- kde2d(mcmc_R1.5_pop200$gamma[-(1:burnIn)], mcmc_R1.5_pop200$beta[-(1:burnIn)], n=50)
filled.contour(z, nlevels=k, col=my.cols, xlab = "", ylab = "", cex.axis = 1.5)
mtext("Gamma", 1, line = 4, cex = 1.5)
mtext("Beta", 2, line = 3, cex = 1.5, outer = FALSE)
@
\caption{Density plot for the first simulation of population size 200 and $R_{0}$ of 1.5 showing the densities of different combinations of $\beta$ and $\gamma$.}
\end{center}
\end{figure}

% Make histogram comparisons of beta and gamma ranges that compares RE and MCMC for example outbreaks? 
% Plot: Histograms comparing RE and MCMC beta and gamma for 6 example scenarios
<<dataplot7, cache=FALSE, echo=FALSE, eval=FALSE, dpi=100, fig.pos="H", fig.height=4, fig.width=6, fig.cap="Data plot", fig=TRUE>>=
# Beta Histogram
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
re_R1.5_pop50_seed1 <- read.csv(paste(dir, "re_pop50_R1.5_g0.15_14.csv", sep=""))
re_R1.5_pop200_seed1 <- read.csv(paste(dir,"re_pop200_R1.5_g0.15_81.csv", sep=""))
re_R1.5_pop1000_seed1 <- read.csv(paste(dir,"re_pop1000_R1.5_g0.15_177.csv", sep=""))
re_R6_pop50_seed1 <- read.csv(paste(dir,"re_pop50_R6_g0.15_2.csv", sep=""))
re_R6_pop200_seed1 <- read.csv(paste(dir,"re_pop200_R6_g0.15_6.csv", sep=""))
re_R6_pop1000_seed1 <- read.csv(paste(dir,"re_pop1000_R6_g0.15_11.csv", sep=""))

mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

letter_size = 1

# Pop. size = 50
par(mfrow = c(2,6), mar = c(4,3.9,1,0.5))
# beta_xaxis <- c(0.002, 0.010)
# gamma_xaxis <- c(0.05, 0.14)
beta_xaxis1.5 <- c(0.0, 0.013)
gamma_xaxis1.5 <-c(0.0, 0.40)

# RE
# RE seed 1
hist(re_R1.5_pop50_seed1$beta[2:nrow(re_R1.5_pop50_seed1)],nclass=30, col="gray", main="RE beta seed 1", xlab="", xlim = beta_xaxis1.5)
abline(v = re_R1.5_pop50_seed1$beta[1], col = "red")
box()
# Pop = 200 & R0 = 1.5
# RE seed 1
hist(re_R1.5_pop200_seed1$beta[2:nrow(re_R1.5_pop200_seed1)],nclass=30, col="gray", main="RE beta seed 1", xlab="", xlim = beta_xaxis1.5)
abline(v = re_R1.5_pop200_seed1$beta[1], col = "red")
box()
# Pop = 1000 & R0 = 1.5
# RE seed 1
hist(re_R1.5_pop1000_seed1$beta[2:nrow(re_R1.5_pop1000_seed1)],nclass=30, col="gray", main="RE beta seed 1", xlab="", xlim = beta_xaxis1.5)
abline(v = re_R1.5_pop1000_seed1$beta[1], col = "red")
box()

# MCMC seed 1
hist(mcmc_R1.5_pop50_seed1$beta[-(1:burnIn)], nclass=30, col = "gray", main="MCMC beta seed 1", xlab = "Beta", xlim = beta_xaxis1.5)
abline(v = mean(mcmc_R1.5_pop50_seed1$beta[-(1:burnIn)]), col = "red")
box()
# MCMC seed 1
hist(mcmc_R1.5_pop200_seed1$beta[-(1:burnIn)], nclass=30, col = "gray", main="MCMC beta seed 1", xlab = "Beta", xlim = beta_xaxis1.5)
abline(v = mean(mcmc_R1.5_pop200_seed1$beta[-(1:burnIn)]), col = "red")
box()
# MCMC seed 1
hist(mcmc_R1.5_pop1000_seed1$beta[-(1:burnIn)], nclass=30, col = "gray", main="MCMC beta seed 1", xlab = "Beta", xlim = beta_xaxis1.5)
abline(v = mean(mcmc_R1.5_pop1000_seed1$beta[-(1:burnIn)]), col = "red")
box()
@

%%%%%%%%%%

\subsection{Markov Chain Monte Carlo with a partly deterministic process}

Running the MCMC with deterministic process for 2.5 million iterations took approximately 20 hours for each outbreak studied.

The $\beta$ posteriors run for the MCMC with a deterministic process show that the $\beta$ estimates did not change much over the course of the 2.5 million iterations for either of the runs with a population size of 1000 or for the outbreak with an $R_{0}$ of 6 and a population size of 50 (Figure 12 C, D, F). The other three outbreaks did see changes in areas of $\beta$ values explored. In addition to this, the stickiness of the $\beta$ posteriors, their tendency to stay in place rather than explore other parameter values, seems to increase with increasing population size.

\begin{figure}[h]
\begin{center}
<<detmcmcbeta, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, height=13, width=19, fig.cap="Data plot", fig=TRUE>>=
# Beta posterior plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "det_mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"det_mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"det_mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"det_mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"det_mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"det_mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

letter_size = 3
iteration_place = 3400
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2,3), mar=c(5,6.5,1.5,1))

burnIn = ((2500000/1000)/100)*23 # 23% burn-in
beta_yaxis50_1 = c(0.002, 0.005)
beta_yaxis200_1 = c(0.0005, 0.0015)
beta_yaxis1000_1 = c(0.00009, 0.00011)
beta_yaxis50_2 = c(0.013, 0.0145)
beta_yaxis200_2 = c(0.0025, 0.004)
beta_yaxis1000_2 = c(0.00105, 0.0012)
# Seed 1, Pop size 50
plot(mcmc_R1.5_pop50_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis50_1, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis50_1), "A", cex = letter_size)
mtext("Beta value", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 1, Pop size 200
plot(mcmc_R1.5_pop200_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis200_1, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis200_1), "B", cex = letter_size)
# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis1000_1, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis1000_1), "C", cex = letter_size)
# Seed 1, Pop size 50
plot(mcmc_R6_pop50_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis50_2, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis50_2), "D", cex = letter_size)
mtext("Beta value", 2, line = 3, cex = yaxis_size, outer = FALSE)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 200
plot(mcmc_R6_pop200_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis200_2, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis200_2), "E", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$beta, type = "l", main = "", xlab = "", ylab = "", ylim = beta_yaxis1000_2, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(beta_yaxis1000_2), "F", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
@
\caption{Posterior trace of $\beta$ values of deterministic MCMC}
\end{center}
\end{figure}

A similar situation is seen for the $\gamma$ posterior traces (Figure 13), the traces stay in place for for the largest population size (Fig. 13 C, F). The other two population sizes saw increases in $\gamma$ over the course of the 2.5 million iterations (Fig. 13 A-B, D-E). Also, as with the $\beta$ posteriors, the $\gamma$ posteriors' stickiness increases with increasing population size.

\begin{figure}[h]
\begin{center}
<<detmcmcgamma, cache=FALSE, echo=FALSE, eval=TRUE, dpi=100, height=13, width=19, fig.cap="Data plot", fig=TRUE>>=
# Beta posterior plots
dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
mcmc_R1.5_pop50_seed1 <- read.csv(paste(dir, "det_mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
mcmc_R1.5_pop200_seed1 <- read.csv(paste(dir,"det_mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
mcmc_R1.5_pop1000_seed1 <- read.csv(paste(dir,"det_mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
mcmc_R6_pop50_seed1 <- read.csv(paste(dir,"det_mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
mcmc_R6_pop200_seed1 <- read.csv(paste(dir,"det_mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
mcmc_R6_pop1000_seed1 <- read.csv(paste(dir,"det_mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

letter_size = 3
iteration_place = 3400
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2,3), mar=c(5,6.5,1.5,1))

burnIn = ((2500000/1000)/100)*23 # 23% burn-in
gamma_yaxis50_1 = c(0.05, 0.2)
gamma_yaxis200_1 = c(0.05, 0.2)
gamma_yaxis1000_1 = c(0.03, 0.07)
gamma_yaxis50_2 = c(0.35, 0.45)
gamma_yaxis200_2 = c(0.3, 0.5)
gamma_yaxis1000_2 = c(0.15, 0.2)
# Seed 1, Pop size 50
plot(mcmc_R1.5_pop50_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis50_1, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis50_1), "A", cex = letter_size)
mtext("Gamma value", 2, line = 3, cex = yaxis_size, outer = FALSE)
# Seed 1, Pop size 200
plot(mcmc_R1.5_pop200_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis200_1, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis200_1), "B", cex = letter_size)
# Seed 1, Pop size 1000
plot(mcmc_R1.5_pop1000_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis1000_1, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis1000_1), "C", cex = letter_size)
# Seed 1, Pop size 50
plot(mcmc_R6_pop50_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis50_2, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis50_2), "D", cex = letter_size)
mtext("Gamm avalue", 2, line = 3, cex = yaxis_size, outer = FALSE)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 200
plot(mcmc_R6_pop200_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis200_2, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis200_2), "E", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
# Seed 1, Pop size 1000
plot(mcmc_R6_pop1000_seed1$gamma, type = "l", main = "", xlab = "", ylab = "", ylim = gamma_yaxis1000_2, cex.axis = number_size)
  abline(v = burnIn, untf = FALSE)
text(iteration_place, 0.95*max(gamma_yaxis1000_2), "F", cex = letter_size)
mtext("Iteration (x10^3)", 1, line = 4, cex = yaxis_size)
@
\caption{Posterior trace of $\gamma$ values of deterministic MCMC}
\end{center}
\end{figure}

When investigating the infectious curves produced by the inferred $\beta$ and $\gamma$ values, it can be seen that the location of the peak is misjudged for population size 50 and 1000 when $R_{0}$ is 1.5 (Fig. 14 A, C), with the height of the peak also being underestimated for population size 50. For population size 200 and $R_{0}$ of 1.5 the height of the peak is underestimated, but its location is more similar to the true simulated peak (Fig 14B). For the outbreaks with an $R_{0}$ of 6, the size of the peak is greatly underestimated for population sizes 50 and 200, though the location of the peak in time is not fully dissimilar from the true peak's location (Fig. 14D-E). For population size 1000, the size of the peak is underestimated, but not as greatly as for the other two population sizes, though the location of the peak in time is estimated to be earlier than for the true curve (Fig. 14F).  

\begin{figure}[h]
\begin{center}
<<detmcmc, cache=TRUE, echo=FALSE, eval=FALSE, dpi=100, height=13, width=17, fig.cap="Data plot", fig=TRUE>>=
# RE example plots
library("deSolve")

true_R1.5_pop50_seed1 <- read.csv("data_pop50_R1.5_g0.15_14.csv")
true_R1.5_pop200_seed1 <- read.csv("data_pop200_R1.5_g0.15_81.csv")
true_R1.5_pop1000_seed1 <- read.csv("data_pop1000_R1.5_g0.15_177.csv")
true_R6_pop50_seed1 <- read.csv("data_pop50_R6_g0.15_2.csv")
true_R6_pop200_seed1 <- read.csv("data_pop200_R6_g0.15_6.csv")
true_R6_pop1000_seed1 <- read.csv("data_pop1000_R6_g0.15_11.csv")

dir <- "/home/evelina/OneDrive/MRes_BMR/Project_1/Work_folder/Data/server_data/"
re_R1.5_pop50_seed1 <- read.csv(paste(dir, "det_mcmc_pop50_R1.5_g0.15_14_loglik.csv", sep=""))
re_R1.5_pop200_seed1 <- read.csv(paste(dir,"det_mcmc_pop200_R1.5_g0.15_81_loglik.csv", sep=""))
re_R1.5_pop1000_seed1 <- read.csv(paste(dir,"det_mcmc_pop1000_R1.5_g0.15_177_loglik.csv", sep=""))
re_R6_pop50_seed1 <- read.csv(paste(dir,"det_mcmc_pop50_R6_g0.15_2_loglik.csv", sep=""))
re_R6_pop200_seed1 <- read.csv(paste(dir,"det_mcmc_pop200_R6_g0.15_6_loglik.csv", sep=""))
re_R6_pop1000_seed1 <- read.csv(paste(dir,"det_mcmc_pop1000_R6_g0.15_11_loglik.csv", sep=""))

burnIn <- 2500*0.23

sir <- function(time, state, param) {
  
  # define model parameters in term of the natural parameters
  beta <- param[1] 
  gamma <- param[2]
  
  with(as.list(c(state, param)), {
    
    dS <- -(beta * S * I) 
    dI <- (beta * S * I) -(gamma * I)
    dR <-  gamma * I
    
    return(list(c(dS, dI, dR)))
  })
}

pre_sir <- function(run_stoch, sse_data){
# Time
timestep <- run_stoch$time[2] - run_stoch$time[1]
end <- max(run_stoch$time)
times <- seq(0, end, by = timestep)

# Initial population: N-1 susceptible, 1 infectious, 0 recovered
init.values = c(
  S = run_stoch$S[1],
  I = run_stoch$I[1],
  R = run_stoch$R[1]
)
N = sum(init.values)

det_sir <- as.data.frame(ode(y = init.values, times = times, func = sir, parms = sse_data[1:2]))
}

letter_size = 3
axis_size = 2.5
yaxis_size = 2
number_size = 2.5

par(mfrow = c(2, 3), mar=c(5,6.5,0.4,0.2))
# R = 1.5, Pop = 50
N = 50
plot(true_R1.5_pop50_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
  lines(true_R1.5_pop50_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
for (i in burnIn:nrow(re_R1.5_pop50_seed1)){
  sir_data <- pre_sir(true_R1.5_pop50_seed1, re_R1.5_pop50_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
text(10, 0.95*N, "A", cex = letter_size)
mtext("Number infected/recovered", 2, line = 4, cex = yaxis_size, outer = FALSE)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 1.5, Pop = 200
N = 200
plot(true_R1.5_pop200_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop200_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
for (i in burnIn:nrow(re_R1.5_pop200_seed1)){
  sir_data <- pre_sir(true_R1.5_pop200_seed1, re_R1.5_pop200_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
text(10, 0.95*N, "B", cex = letter_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 1.5, Pop = 1000
N = 1000
plot(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R1.5_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
for (i in burnIn:nrow(re_R1.5_pop1000_seed1)){
  sir_data <- pre_sir(true_R1.5_pop1000_seed1, re_R1.5_pop1000_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
text(10, 0.95*N, "C", cex = letter_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 6, Pop = 50
N = 50
plot(true_R6_pop50_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop50_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
for (i in 2:nrow(re_R1.5_pop50_seed1)){
  sir_data <- pre_sir(true_R6_pop50_seed1, re_R6_pop50_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
text(10, 0.95*N, "D", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
mtext("Number infected/recovered", 2, line = 4, cex = yaxis_size, outer = FALSE)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 6, Pop = 200
N = 200
plot(true_R6_pop200_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop200_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
for (i in 2:nrow(re_R1.5_pop200_seed1)){
  sir_data <- pre_sir(true_R6_pop200_seed1, re_R6_pop200_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
text(10, 0.95*N, "E", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
# R = 6, Pop = 1000
N = 1000
plot(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "white", xlab = "", ylab = "", cex.axis = number_size)
lines(true_R6_pop1000_seed1$I, ylim = c(0, N), type = "l", col = "red", lwd = 3)
for (i in 2:nrow(re_R6_pop1000_seed1)){
  sir_data <- pre_sir(true_R6_pop1000_seed1, re_R6_pop1000_seed1[i,])
  lines(sir_data$I, type = "l", lty = 2, col = "grey", xlab = " ", ylab = " ", lwd = 0.5)
}
text(10, 0.95*N, "F", cex = letter_size)
mtext("Timestep", 1, line = 4, cex = yaxis_size)
# legend(100, 0.8*N, c("True infected", "Deterministic infected"), pch = 1, col = c("red", "black"), bty = "n")
@
\caption{Infectious curves for MCMC with a deterministic process}
\end{center}
\end{figure}

%%%%%%%%%%%%%%%%
%% Discussion %%
%%%%%%%%%%%%%%%%

\newpage
\section{Discussion}
% 5-10 pages

%%%%%%%%%%
\subsection{Summary of findings}

Both RE and MCMC inference methods observe the same positive correlation between $\beta$ and $\gamma$ as was determined by the heatmap for RE (Fig. X) and the density plot for the MCMC (Fig. Y). The positive correlation is likely due to there being less of a difference whether the rates of infection and recovery are both increased or both reduced, as the net number who become infected remains the same. Though both methods observe the same trend, it can be noted that the 95\% intervals obtained through bootstrapping for the RE are narrower than the 95\% credible interval of the MCMC. Possibly relating to this, the 95\% interval of the RE method includes the true $\beta$ and $\gamma$ values less often than the 95\% credible interval of the MCMC method (Reference tables). It could be that if the MCMCs would have been run for more iterations and until convergence looked more likely, the 95\% credible interval would have also narrowed. That being said, it is unlikely that even this narrower credible interval would have been as narrow as the RE interval, as the difference in interval width was still prevalent for a population size of 50 and $R_{0}$ of 6, though the runs seemed seemed to have converged during the 3.5 million iteration runs (Fig. 7D, Fig. 8D).

Though the $\beta$ estimates for the RE method tended to be below the true value when $R_{0}$ was 1.5 and above the true value when $R_{0}$ was 6 (Table 1), the $\gamma$ 95\% intervals included the true value more often for the higher $R_{0}$ than the lower $R_{0}$ and more often as population size increased (Table 2). Therefore, it could be argued that the RE method gave ranges of $\beta$ and $\gamma$ that were closest to their respective true values for outbreaks with the higher $R_{0}$. Within this outbreak severity, the RE method fared better with increasing population size. This could be due to stochasticity being reduced with increasing population size as seen in Figure 3, where outbreaks with a population size of 1000 had smoother epidemic curves than outbreaks in populations of 50.

Compared to the RE method, the MCMC method was more reliable with including the true $\beta$ and $\gamma$ values in its 95\% credible intervals (reference tables), though all runs would likely have benefitted from being run for more than 3.5 million iterations. The running time of the MCMC method was slower than that of the RE inference method. Running 1000 iterations of the RE method took approximately 20 minutes, while running 3.5 million iterations took over 20 hours and 17.5 million iterations over 120 hours with the running time increasing with population size. 

The MCMC with a deterministic process for inference did not perform as well as the RE or normal MCMC method for the cases considered in this project. Based on the posterior traces it could be that with finetuning of the proposal function, the method could provide better estimates for $\beta$ and $\gamma$ than the ones presented in this report, though whether these estimates would exceed those of the RE is not certain.

\subsection{Open questions for discussion}
Considering that the RE inference method experienced improved $\beta$ and $\gamma$ estimates with increasing population size and higher $R_{0}$, it could be that eventually the RE inference method may consistently include the true $\beta$ and $\gamma$ values if investigated for even higher population sizes and $R_{0}$s. As the running time and number of iterations required for convergence for the MCMC increases with increasing population size, eventually a trade-off of the narrower 95\% intervals for a much quicker running time might become a reasonable option. Further investigations with larger population sizes and $R_{0}$s could be conducted to gain a better understanding of when this trade-off would become cost effective. The MCMC inference method devised in this project is also not optimised for efficiency, so it is possible that the running time of the MCMC could be shortened in further work.

\subsection{Limitations}
Only one type of compartmental model, a closed SIR model, was considered in this project. Additionally, the model is very simple with no spatial modelling or other complicating matters. It could be argued though that if the aim of a study is to conduct complicated models including spatial aspects, a stochastic process must be used regardless and thus the question of whether or not to use a deterministic inference method becomes obsolete. 

Additionally, as mentioned previously, the MCMCs could have been run for longer than 3.5 million or even 17.5 million iterations to reach full convergence. Additionally, the MCMCs could have been repeated for the different outbreaks from different parameter starting points to investigate if the runs from different starting points converge at similar $\beta$ and $\gamma$ values. That being said, the aim of this project was to compare different inference methods rather than perfect one method completely.

\subsection{Conclusions}
When estimating the ranges of $\beta$ and $\gamma$ through 95\% credible intervals and 95\% intervals for the MCMC and RE inference methods respecively, the MCMC inference method's ranges included the true $\beta$ and $\gamma$ values more often than the RE method. Within the RE method, the 95\% intervals were more consistent with including the true $\beta$ and $\gamma$ values as population size increased and with higher $R_{0}$. Further work comparing the inference methods for higher $R_{0}$s and population sizes may find that eventually the RE inference method's 95\% interval might also include the true $\beta$ and $\gamma$ values and be quicker to run than a MCMC. 

%%%%%%%%%%%%%%%%
%% References %%
%%%%%%%%%%%%%%%%

\newpage
\section{References}

\bibliography{/home/evelina/Documents/Mendeley/MRes_stochastic_deterministic.bib}

R Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.
% citation()
Karline Soetaert, Thomas Petzoldt, R. Woodrow Setzer (2010). Solving Differential Equations in R: Package deSolve. Journal of Statistical Software, 33(9), 1--25. URL http://www.jstatsoft.org/v33/i09/ DOI 10.18637/jss.v033.i09
% citation("deSolve")

% 5 pages

%%%%%%%%%%

%%%%%%%%%%%%%%
%% Appendix %%
%%%%%%%%%%%%%%

% \section{Appendix}

\end{document}